{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Arun Ramesh, University of Houston. https://rpglab.github.io/people/Arun-Venkatesh-Ramesh/\n",
    "#### Source webpage: https://rpglab.github.io/resources/FL-ML-R-SCUC_Python/\n",
    "#### If you use any codes/data here for your work, please cite the following paper: \n",
    "#####       Arun Venkatesh Ramesh and Xingpeng Li, “Feasibility Layer Aided Machine Learning Approach for Day-Ahead Operations”, IEEE Transactions on Power Systems, Apr. 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "\n",
    "import sys\n",
    "nums = np.arange(2000)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import csv\n",
    "import time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       88.95783123018604  79.89731138266708  74.13152602515503  \\\n",
      "0             70.842516          63.627074          59.035430   \n",
      "1            102.465737          92.029412          85.388114   \n",
      "2            103.989126          93.397641          86.657605   \n",
      "3             67.207355          60.362162          56.006130   \n",
      "4             93.489390          83.967322          77.907825   \n",
      "...                 ...                ...                ...   \n",
      "1794          76.630947          71.840607          65.623164   \n",
      "1795          78.200704          68.007509          65.384535   \n",
      "1796          87.128307          77.862964          72.939164   \n",
      "1797          77.172511          71.257205          65.388665   \n",
      "1798          94.566878          82.100946          75.922571   \n",
      "\n",
      "      126.84727786526528  58.4815371976223  121.90517613025493  \\\n",
      "0             101.016180         46.572395           97.080485   \n",
      "1             146.108550         67.361734          140.416009   \n",
      "2             148.280791         68.363222          142.503618   \n",
      "3              95.832711         44.182613           92.098969   \n",
      "4             133.308945         61.460617          128.115090   \n",
      "...                  ...               ...                 ...   \n",
      "1794          108.960015         52.638486          104.727079   \n",
      "1795          112.729228         51.302828          109.239296   \n",
      "1796          123.990679         58.809417          122.145616   \n",
      "1797          108.834894         51.702031          109.154311   \n",
      "1798          132.313960         61.867234          127.687711   \n",
      "\n",
      "      51.0683845951068  70.01310791264642  144.14463393780144  \\\n",
      "0            40.668852          55.755684          114.791114   \n",
      "1            58.822923          80.644330          166.032444   \n",
      "2            59.697461          81.843294          168.500899   \n",
      "3            38.582000          52.894678          108.900807   \n",
      "4            53.669835          73.579612          151.487437   \n",
      "...                ...                ...                 ...   \n",
      "1794         45.737432          60.054959          127.612125   \n",
      "1795         45.118923          59.408408          123.893277   \n",
      "1796         49.671851          68.130635          143.887170   \n",
      "1797         44.839680          61.689065          126.461858   \n",
      "1798         54.371961          71.496726          147.356793   \n",
      "\n",
      "      82.36836225017225  ...  134.88201235527217  85.36836225017225.1  0.163  \\\n",
      "0             65.594922  ...          108.379977            68.594922      0   \n",
      "1             94.875682  ...          154.643578            97.875682      0   \n",
      "2             96.286228  ...          156.872240            99.286228      0   \n",
      "3             62.229033  ...          103.061872            65.229033      0   \n",
      "4             86.564250  ...          141.511515            89.564250      0   \n",
      "...                 ...  ...                 ...                  ...    ...   \n",
      "1794          72.137323  ...          120.317703            73.678827      0   \n",
      "1795          71.607912  ...          119.901775            76.821454      0   \n",
      "1796          81.079173  ...          130.637795            83.511229      0   \n",
      "1797          72.139059  ...          115.944819            74.232178      0   \n",
      "1798          87.310908  ...          140.515200            87.052422      0   \n",
      "\n",
      "      138.29674684527905  76.83152602515503.1  55.489435462611965  0.164  \\\n",
      "0             111.123774            61.735430           44.586699      0   \n",
      "1             158.558605            88.088114           63.619193      0   \n",
      "2             160.843689            89.357605           64.536048      0   \n",
      "3             105.671033            58.706130           42.398871      0   \n",
      "4             145.094085            80.607825           58.216762      0   \n",
      "...                  ...                  ...                 ...    ...   \n",
      "1794          120.828823            67.781681           49.937268      0   \n",
      "1795          121.236911            66.470685           48.419661      0   \n",
      "1796          136.242006            76.562699           55.081633      0   \n",
      "1797          123.129715            66.832212           48.001125      0   \n",
      "1798          143.127598            78.288603           57.423091      0   \n",
      "\n",
      "      0.165  0.166  0.167  \n",
      "0         0      0      0  \n",
      "1         0      0      0  \n",
      "2         0      0      0  \n",
      "3         0      0      0  \n",
      "4         0      0      0  \n",
      "...     ...    ...    ...  \n",
      "1794      0      0      0  \n",
      "1795      0      0      0  \n",
      "1796      0      0      0  \n",
      "1797      0      0      0  \n",
      "1798      0      0      0  \n",
      "\n",
      "[1799 rows x 576 columns]>\n",
      "<bound method DataFrame.info of       0  0.1  1  1.1  0.2  0.3  1.2  1.3  0.4  0.5  ...  1.398  1.399  1.400  \\\n",
      "0     0    0  0    0    0    0    1    1    0    0  ...      1      1      1   \n",
      "1     0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "2     0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "3     0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "4     0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "...  ..  ... ..  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...    ...   \n",
      "1794  0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "1795  0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "1796  0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "1797  0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "1798  0    0  1    1    0    0    1    1    0    0  ...      1      1      1   \n",
      "\n",
      "      1.401  1.402  1.403  1.404  1.405  1.406  1.407  \n",
      "0         1      1      1      1      1      1      1  \n",
      "1         1      1      1      1      1      1      1  \n",
      "2         1      1      1      1      1      1      1  \n",
      "3         1      1      1      1      1      1      0  \n",
      "4         1      1      1      1      1      1      1  \n",
      "...     ...    ...    ...    ...    ...    ...    ...  \n",
      "1794      1      1      1      1      1      1      1  \n",
      "1795      1      1      1      1      1      1      1  \n",
      "1796      1      1      1      1      1      1      1  \n",
      "1797      1      1      1      1      1      1      1  \n",
      "1798      1      1      1      1      1      1      1  \n",
      "\n",
      "[1799 rows x 792 columns]>\n",
      "1440\n",
      "1440\n",
      "359\n",
      "359\n",
      "[ 282  268  764 1015 1347 1641 1298 1104  674 1758  924 1443  348  275\n",
      "  852 1059 1208  111 1138  258  231   47  779  186  301  406 1472  264\n",
      "  661 1539 1087 1675  625 1785  400 1203   48 1325 1030  421  941 1078\n",
      " 1711 1515 1083  936  158 1285 1482  724 1005 1047 1423  507  478 1678\n",
      "  899  108 1084 1410  202 1403  241 1068 1215  102 1451 1279  336 1058\n",
      "  628  194  325  718 1385  858  790 1491  786 1737  925  561  361 1529\n",
      "   75 1511 1220 1408 1556 1618  304  643 1513  285  177  759  636 1020\n",
      " 1454  446 1323 1593  161 1626  563 1429  659  801  120  335 1469  281\n",
      "   37 1336  547 1756 1752  807  181  592  227  821 1100  536  368  750\n",
      "  631  607  992 1135  824 1313  634 1290  919 1468   60 1118 1715  535\n",
      "  510  675 1409  638  267 1353  126 1074 1749 1252   98 1092 1479 1488\n",
      " 1577  386 1724  614 1035  955  486 1205 1199  698 1578 1729  599   82\n",
      " 1730  418  389 1210 1548  984  553 1048 1204 1764  248  778 1011  190\n",
      "  528 1218 1060 1291  948  133 1224  771 1611   91  683  774  330  297\n",
      " 1267 1782 1497 1173   53 1036  863  331 1171  382  857  737  223  708\n",
      "  107  546   65  480 1244 1361 1551  167  309 1398 1141 1094  827  833\n",
      "    8  537 1475  442 1633 1276  302  573  613    3 1243 1766  587 1708\n",
      " 1302  372 1693 1501  556  826  453 1396 1557  701 1283  851  671 1722\n",
      "  435  763  292 1399 1565  894  872  385  745 1775 1772  950 1673  140\n",
      "  839 1264 1609  572  351  424 1181 1449  525 1006  757 1567 1717 1720\n",
      "    0  672  649  462  653  115  823  201   30  527 1037  799 1315  293\n",
      " 1317 1262  432  408  608 1273  305  598 1149  447   39  703 1489  660\n",
      "   80  577  101 1631 1535  791  895  697  593 1461 1647 1263  816 1364\n",
      " 1257  834  341 1227  612  983  589 1687  283  303  742 1271  996   40\n",
      " 1508   58 1401  255 1231 1369  375  555  825 1747  403  961  119 1709\n",
      " 1470 1604 1115 1603  366  169 1644 1176 1117 1157 1628  270 1392  729\n",
      "  767 1123 1167 1197  993  679 1499  208  288  104  236  713  512   22\n",
      "  204  711  693 1536 1038 1466 1383 1796 1465 1750  534 1480 1066   19\n",
      " 1441  596 1322   81 1082   51  259  428 1684  396 1053 1531  654 1177\n",
      " 1574 1292 1073   49   94 1646  761  299 1134 1467  664  874 1379 1172\n",
      " 1452 1587 1670 1655  968  434  730 1595 1357  531 1081  813  898  887\n",
      " 1388 1406 1162  228 1374 1458 1351 1605 1505  286 1051  726 1098 1649\n",
      "  464 1645  977  135 1759  859 1477  211 1619 1780  815 1698   88  622\n",
      "  705  298 1330 1783  647  845  650 1079  353  918 1415  808 1591 1127\n",
      "   45  812  700  414  602 1562 1090  192   16 1549 1382  481  870 1065\n",
      "  620 1229  110 1610  571  804 1148   87  819  916  321 1166   62  146\n",
      " 1435 1790  976 1652 1777 1706 1699   56  142  579  725 1421 1761  736\n",
      "  198  460  159  860 1795 1125 1440   83 1473 1307 1376 1395  427  289\n",
      "  529  957 1397 1178  401  154 1389 1144  926  861 1733 1457 1664 1456\n",
      " 1156 1426  314  793  558  426 1367  881 1524 1342  490  521  575  491\n",
      "  422  995 1152  443  632 1721  986 1701 1246 1266  840  623  409   12\n",
      " 1494  404 1333   73  195  399  308  644  982 1370 1185  619  215  810\n",
      "  163  702 1373  559  868  538  640  789 1450  280 1728  496  311  131\n",
      "  251 1534  494 1089 1762  902  943 1784  584 1159 1013  940  359  942\n",
      "  820  777 1228  239  350 1010 1029 1335  669 1213  707 1550  570 1131\n",
      "  952  991 1660   27  425  854 1340 1575  487  769 1256 1384 1621  495\n",
      "  597  655 1103   90   50  262  885  953  148 1282  390 1765   78 1481\n",
      " 1008 1237   35 1223  900  772  748  323 1269    6 1116 1748  452 1786\n",
      " 1553  216  921  395 1638  503  383  310 1017 1234  520 1651 1520 1412\n",
      "  205 1683 1194 1338 1363 1704 1179  663  678  733  574 1238  629  315\n",
      "  966 1579 1368 1377  913 1189 1543 1459 1070 1430 1416  188  189  768\n",
      "  662  242 1597  828  688  498   41  448   99 1108  582  802  484  720\n",
      " 1710  250  436   76 1419  719  516  904 1163  685 1297  439  419 1259\n",
      "  502 1041 1755 1045  987  200  349 1128 1028  635  888 1248  318  906\n",
      " 1310  581  355 1545  985  493  723  180  244 1528  274 1686  576  392\n",
      " 1287  220  234   34   85  746  156 1130 1753  931  363  927 1097  380\n",
      " 1634 1195  509   67 1602 1437 1009 1057  979  893  471 1032  393 1119\n",
      " 1635  922 1309  347   74  329 1476 1474 1027  134  103    9 1196  543\n",
      "   10  935  639  766 1245 1334  994  284 1714  616  370  920 1663 1447\n",
      "  125  407  962 1272  846 1504 1522 1648  541  139 1132  260  473  165\n",
      "  226 1744  692  191  306 1424 1700 1569  482 1445 1270 1249 1694 1114\n",
      " 1348  320 1428 1541  754   17  890  430 1754 1774 1582 1165 1526  207\n",
      "  237 1184  785 1043 1147  345 1386 1225 1044 1657  340  891  457  175\n",
      "  549 1517  300 1561  459  160 1371 1542 1026  474  912  997  990  463\n",
      " 1671  841 1180  326 1004 1085  972 1601 1484  892   59   13 1788  959\n",
      "  387  523 1086   26 1233  603  970  322 1685 1580 1650  866 1420 1080\n",
      "  441 1740  295  554  256  560  830 1003 1462  880 1012  307   72  257\n",
      " 1209    2 1632 1692 1767  680 1328  367 1546  694  929 1352 1552  479\n",
      "  557  969 1253  909 1124  585  117 1219 1512 1105  682 1493    5 1668\n",
      "  466 1381 1211 1000  842  445  136   11 1198 1268  332  877  951  776\n",
      "  604  568 1145 1153 1241 1725   54 1129  233 1742   84  641  415 1014\n",
      "   64 1460 1329  187  755 1483  151  831 1378 1471  388  137  731  172\n",
      " 1071  530 1745  765  455  735 1112 1402 1359  594 1554 1615  374 1629\n",
      "    1  709  937 1614 1537  670   32  238  127  354  164 1247  492  472\n",
      " 1559 1226 1304   89 1158   97 1023 1318  449  550 1102  218  178  433\n",
      "  567 1418  741 1146  483 1594 1413  437  780  548  853 1600  782 1296\n",
      " 1093 1242 1007 1143 1293  673 1713  686 1201 1509  817  752  121  699\n",
      "  876 1109 1040 1691  578  855 1240   38   31 1250  106   23  710   69\n",
      " 1787 1576 1331 1623 1583  265 1183 1016 1064  504  276  809  339 1606\n",
      "  945 1365  185  798  930  744  978   61  797 1216 1616 1540  193  646\n",
      "   33 1343  800   57  938 1206  358 1069 1422   68  291   46  923  277\n",
      " 1653  224  864  381 1301  364 1712 1024  773 1387   66 1055  867   28\n",
      "  294  113  245 1022  980  411 1400 1286  116 1666 1444  247  665 1703\n",
      " 1741   92  114  254  429  588 1438  118  132 1289 1681  246 1695  775\n",
      "  552 1113 1221 1770 1308 1643  651 1170 1142 1265 1726  533  862 1230\n",
      " 1281  897 1769 1734  676   14  500 1463 1106 1506  600  875  273  684\n",
      " 1341 1133  371  271  605  214 1344  344  838  147 1021 1564  412  783\n",
      "  342  947  747  173  377  738 1314   52   18  221 1260 1358 1719 1140\n",
      "   95  261 1436 1439  179 1126  716 1696  184  467  903   71 1169 1781\n",
      "  346 1207   29  796 1063  157  932  658 1589  394 1076  988 1427 1274\n",
      "  402  989  677 1251  822  963  835 1033 1487  939 1054 1101  691 1446\n",
      "  334  873  805    7  517  197  296 1432 1599 1507  122  378 1062 1568\n",
      " 1503  162 1186 1091  124  551    4  915  958 1530  611  287  956 1789\n",
      " 1464 1355  908  506  356  352  844 1154  836  946  667  886 1284 1498\n",
      "  333  153  787  501  721  373  590  312   42 1390  645 1525  971 1674\n",
      "  522 1453  762 1519 1658 1586  704 1723 1608 1407  944  168 1563  360\n",
      " 1018 1776  743  272  519  814  818  734 1688 1570 1394 1778 1121  128\n",
      "  998 1598  544  379  203  343 1533 1667  518 1639  488 1261 1768  917\n",
      "  232  794 1682 1122  514 1779  511  112 1718  217  499 1760  934  225\n",
      " 1042 1192 1792 1316 1662  397  540  328  795  848 1584 1732 1636   93\n",
      "  213  770  337  803  212  618 1139 1182 1168 1136   36  105  362  850\n",
      "  756  758  365  856 1510 1794  565 1375  249  476 1705 1188  781  454\n",
      " 1625 1200 1107  230 1319  652   70  610 1174 1727 1672 1746  410 1656\n",
      " 1151  338 1025   43  539  601 1332  965 1613 1434  171  417  837 1690\n",
      " 1496  806  882 1676  637  423  727  967 1339  376  524 1751  438 1547\n",
      "  150 1798 1630  981  954 1620 1433  143  717  526  583  975  566 1232\n",
      "  440 1155 1404  174 1294 1431 1518  123  138  879 1075  732  624 1299\n",
      "  784 1366 1280  182  617 1324  690 1573  240 1254 1350  458  681  465\n",
      " 1187 1191  145  206 1212 1555  324  657 1642  714 1659 1702   79 1637\n",
      " 1622  687  166  229 1738 1588  740  100  290  444  878 1455 1077  739\n",
      "  391   86 1797  666 1275 1523 1617  475 1295   44  788 1002 1137   24\n",
      " 1235  832 1193  591 1771  973 1544 1056  109 1160 1354  222 1052 1311\n",
      "  722   55 1773  253 1707 1072 1492  642  545  477  949 1571  843   63\n",
      "  413  384 1697  974 1346  884  451 1624 1258  656 1581 1486 1448 1485\n",
      " 1327  369  689  219 1680 1320   21  760  869  420 1349  199  450 1161\n",
      " 1019 1560  911  696  811 1236 1763  910 1521 1049  505 1627 1255  405\n",
      " 1592  317  183 1120 1665  609  626  485  278  630   20  170 1425  901\n",
      " 1039 1590  176  327  706 1222  470 1654  266  615 1516  130  865 1731\n",
      " 1362 1661  489 1596  606 1217 1164  416 1500  152  889  849  279 1034\n",
      "  269   96  210 1532  569 1739  871 1572 1566  532 1736 1356 1099  712\n",
      "   77  263 1793  149 1735 1538 1743  469  564  461 1277  896 1393 1345\n",
      "  695 1175  928 1326 1214  586 1372  243 1111  751 1679 1716 1442 1312\n",
      "  648 1190  595  313  933  155 1380 1405 1303 1150  999 1046 1640 1689\n",
      " 1306 1495 1391   25  196 1088   15 1490 1321  883  621 1360 1050 1612\n",
      " 1067  497  792  964  515 1757 1585 1478 1411 1095  542  456  633  431\n",
      "  627 1677  728 1288  209  316  513 1337 1558  829  319 1031 1417  141\n",
      " 1110 1502 1527  753 1001 1239  580  562  398  668 1514  252  907  468\n",
      "  914  357 1278 1300 1202 1305 1414  508  749 1607  129  144  960  847\n",
      " 1669  715  905 1791 1096  235 1061]\n"
     ]
    }
   ],
   "source": [
    "##### data set 24 Bus 8 Prd\n",
    "\n",
    "dfX_24 = pd.read_csv(\"demand24BusWBCorr24Prd.txt\")\n",
    "dfY_24 = pd.read_csv(\"commitment24BusWBCorr24Prd.txt\")\n",
    "\n",
    "print(dfX_24.info)\n",
    "print(dfY_24.info)\n",
    "\n",
    "x = dfX_24.to_numpy()\n",
    "#x = np.delete(x,0,1) #delete column one sample number\n",
    "x = x/100\n",
    "#print(x[1])\n",
    "\n",
    "y = dfY_24.to_numpy()\n",
    "#y = np.delete(y,0,1) #delete column one sample number\n",
    "#print(y[1])\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 20% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 5\n",
    "(x_train, x_test) = x[:split_at], x[split_at:]\n",
    "(y_train, y_test) = y[:split_at], y[split_at:]\n",
    "\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "\n",
    "print(indices)\n",
    "\n",
    "#print(x_train[1])\n",
    "#print(y_train[1])\n",
    "\n",
    "#print(x_test[1])\n",
    "#print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 576)\n",
      "(1440, 792)\n",
      "(359, 576)\n",
      "(359, 792)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    w = np.zeros(shape=(dim,792))\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1. / ( 1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #print(m)\n",
    "    \n",
    "    #print(w.shape)\n",
    "    #print(X.shape)\n",
    "    #print(b)\n",
    "    b = np.sum(b) #try b.T\n",
    "    #print(b)\n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)             # compute activation\n",
    "    #print(A.shape)\n",
    "    #print(Y.shape)\n",
    "    cost = (-1. / m) * np.sum((Y*np.log(A) + (1 - Y)*np.log(1-A)), axis=1)    # compute cost\n",
    "    #print(cost.shape)\n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    dw = (1./m)*np.dot(X,((A-Y).T))\n",
    "    db = (1./m)*np.sum(A-Y, axis=1)\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == (792,))\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        w = w - learning_rate*dw\n",
    "        b = b -  learning_rate*db\n",
    "        \n",
    "        # Record the costs\n",
    "        #if i % 100 == 0:\n",
    "        costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        #if print_cost and i % 100 == 0:\n",
    "        #    print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    #Y_prediction = np.zeros((792, m))\n",
    "    w = w.reshape(X.shape[0], 792)\n",
    "    b = np.sum(b)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities commitment\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    #print (A.shape)\n",
    "    #print(A.T)        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.005, print_cost = False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # initialize parameters with zeros (≈ 1 line of code)\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 1440)\n",
      "(792, 1440)\n",
      "learning rate is:  0.001\n",
      "train accuracy: 94.84619470400345 %\n",
      "test accuracy: 94.93997875149915 %\n",
      "training time:  87.86160290000004\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.003\n",
      "train accuracy: 95.2737447026796 %\n",
      "test accuracy: 95.37363311977859 %\n",
      "training time:  86.15549179999994\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.005\n",
      "train accuracy: 95.51031158958968 %\n",
      "test accuracy: 95.61690024698231 %\n",
      "training time:  86.65880850000008\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.008\n",
      "train accuracy: 95.71553617199382 %\n",
      "test accuracy: 95.8294577411283 %\n",
      "training time:  88.1274899\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.01\n",
      "train accuracy: 95.80877498037887 %\n",
      "test accuracy: 95.92618047671192 %\n",
      "training time:  87.13582940000003\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.03\n",
      "train accuracy: 96.06378282639358 %\n",
      "test accuracy: 96.1943977740545 %\n",
      "training time:  84.8642178\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9f7c41a8f593>:31: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-1. / m) * np.sum((Y*np.log(A) + (1 - Y)*np.log(1-A)), axis=1)    # compute cost\n",
      "<ipython-input-8-9f7c41a8f593>:31: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (-1. / m) * np.sum((Y*np.log(A) + (1 - Y)*np.log(1-A)), axis=1)    # compute cost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.08634309789433 %\n",
      "test accuracy: 96.2723047884715 %\n",
      "training time:  86.68162519999998\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "\n",
    "learning_rates = [0.001, 0.003, 0.005, 0.008, 0.01, 0.03, 0.05]\n",
    "#learning_rates = [0.01]\n",
    "models = {}\n",
    "for i in learning_rates:\n",
    "    start = timer()\n",
    "    print (\"learning rate is: \",i)\n",
    "    models[i] = model(x_train, y_train, x_test, y_test, num_iterations = 1000, learning_rate = i, print_cost = True)\n",
    "    end = timer()\n",
    "    print(\"training time: \",end - start)\n",
    "    print (\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is:  0.001\n",
      "test accuracy: 96.72807461804676 %\n",
      "train accuracy: 96.57915965207631 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.003\n",
      "test accuracy: 96.9936130103261 %\n",
      "train accuracy: 96.80371422558923 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.005\n",
      "test accuracy: 97.17298331504459 %\n",
      "train accuracy: 96.9302398989899 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.008\n",
      "test accuracy: 97.39455839734391 %\n",
      "train accuracy: 97.11235620089786 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.01\n",
      "test accuracy: 97.43746658788442 %\n",
      "train accuracy: 97.16128296857464 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.03\n",
      "test accuracy: 96.58000619003404 %\n",
      "train accuracy: 96.43614969135803 %\n",
      "-------------------------------------------------------\n",
      "learning rate is:  0.05\n",
      "test accuracy: 96.14951745870965 %\n",
      "train accuracy: 96.02141203703704 %\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in learning_rates:\n",
    "    print (\"learning rate is: \",i)\n",
    "    w = models[i][\"w\"]\n",
    "    b = models[i][\"b\"]\n",
    "    A_prediction_test = predict(w, b, x_test)\n",
    "    A_prediction_test = A_prediction_test.T\n",
    "    \n",
    "    m = A_prediction_test.shape[0]\n",
    "    Y_test_hackFull = np.zeros((m,A_prediction_test.shape[1]))\n",
    "    P = 0.7\n",
    "\n",
    "    for j in range(m):\n",
    "        for i in range(A_prediction_test.shape[1]):\n",
    "        \n",
    "            # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "            if A_prediction_test[j, i] >= P:\n",
    "                Y_test_hackFull[j, i] = 1\n",
    "            \n",
    "            else:\n",
    "                Y_test_hackFull[j, i] = 0\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_test.T - Y_test_hackFull)) * 100))\n",
    "    \n",
    "    A_prediction_train = predict(w, b, x_train)\n",
    "    A_prediction_train = A_prediction_train.T\n",
    "    \n",
    "    m = A_prediction_train.shape[0]\n",
    "    Y_train_hackFull = np.zeros((m,A_prediction_train.shape[1]))\n",
    "    \n",
    "    for j in range(m):\n",
    "        for i in range(A_prediction_train.shape[1]):\n",
    "        \n",
    "            # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "            if A_prediction_train[j, i] >= P:\n",
    "                Y_train_hackFull[j, i] = 1\n",
    "            \n",
    "            else:\n",
    "                Y_train_hackFull[j, i] = 0\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_train.T - Y_train_hackFull)) * 100))\n",
    "    print (\"-------------------------------------------------------\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is:  0.01\n",
      "test accuracy: 97.43746658788442 %\n",
      "train accuracy: 97.16128296857464 %\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0.01\n",
    "print (\"learning rate is: \",i)\n",
    "w = models[i][\"w\"]\n",
    "b = models[i][\"b\"]\n",
    "A_prediction_test = predict(w, b, x_test)\n",
    "A_prediction_test = A_prediction_test.T\n",
    "    \n",
    "m = A_prediction_test.shape[0]\n",
    "Y_test_hackFull = np.zeros((m,A_prediction_test.shape[1]))\n",
    "P = 0.7\n",
    "\n",
    "for j in range(m):\n",
    "    for k in range(A_prediction_test.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A_prediction_test[j, k] >= P:\n",
    "            Y_test_hackFull[j, k] = 1\n",
    "            \n",
    "        else:\n",
    "            Y_test_hackFull[j, k] = 0\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_test.T - Y_test_hackFull)) * 100))\n",
    "    \n",
    "A_prediction_train = predict(w, b, x_train)\n",
    "A_prediction_train = A_prediction_train.T\n",
    "    \n",
    "m = A_prediction_train.shape[0]\n",
    "Y_train_hackFull = np.zeros((m,A_prediction_train.shape[1]))\n",
    "    \n",
    "for j in range(m):\n",
    "    for k in range(A_prediction_train.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A_prediction_train[j, k] >= P:\n",
    "            Y_train_hackFull[j, k] = 1\n",
    "            \n",
    "        else:\n",
    "            Y_train_hackFull[j, k] = 0\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_train.T - Y_train_hackFull)) * 100))\n",
    "print (\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"commitment24Bus24PrdTestSample4Ampl.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(Y_test_hackFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_round = np.around(x_test, decimals=4)\n",
    "x_test_round = x_test_round.T\n",
    "with open(\"demand24Bus24PrdTestSample4Ampl.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(x_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prediction_test_round = np.around(A_prediction_test, decimals=6)\n",
    "#A_prediction_test_round = A_prediction_test_round.T\n",
    "with open(\"probabilities24Bus24PrdTestSample4Ampl.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(A_prediction_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"UgtAct24Bus24PrdTest4Ampl.txt\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "    csvWriter.writerows(y_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_round = np.around(x_train, decimals=3)\n",
    "x_train_round = x_train_round.T\n",
    "with open(\"demand24PrdTrainSample4Ampl.txt\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "    csvWriter.writerows(x_train_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prediction_train_round = np.around(A_prediction_train, decimals=6)\n",
    "with open(\"probabilities24Bus24PrdTrainSample4Ampl.txt\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "    csvWriter.writerows(A_prediction_train_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"UgtAct24Bus24PrdTrain4Ampl.txt\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
    "    csvWriter.writerows(y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1799 into shape (1,1499)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-75c707239cd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnpindice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1499\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indiceshorizontal.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w+\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_csv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#index(indices) 1201-1500 test case 299 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcsvWriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_csv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcsvWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpindice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"indicesvertical.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w+\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_csv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#index(indices) 1201-1500 test case 299 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1799 into shape (1,1499)"
     ]
    }
   ],
   "source": [
    "npindice = np.reshape(indices, (1,1499))\n",
    "with open(\"indiceshorizontal.csv\",\"w+\",newline=\"\") as my_csv: #index(indices) 1201-1500 test case 299 samples\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(npindice) \n",
    "with open(\"indicesvertical.csv\",\"w+\",newline=\"\") as my_csv: #index(indices) 1201-1500 test case 299 samples\n",
    "    csvWriter = csv.writer(my_csv,delimiter='\\n')\n",
    "    csvWriter.writerows(npindice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       90.13728903773256  80.95663922833387  75.11440753144379  \\\n",
      "0             67.493145          60.618843          56.244287   \n",
      "1            107.022171          96.121765          89.185142   \n",
      "2            108.926408          97.832052          90.772007   \n",
      "3             62.949194          56.537702          52.457662   \n",
      "4             95.801737          86.044153          79.834781   \n",
      "...                 ...                ...                ...   \n",
      "1494         101.205071          83.534633          79.818072   \n",
      "1495          84.521178          78.343324          74.534879   \n",
      "1496          92.821142          84.133780          89.090335   \n",
      "1497          78.007085          86.473328          79.682256   \n",
      "1498          85.612332          75.013867          67.089895   \n",
      "\n",
      "      128.52909733158162  59.25692149702789  123.5214701628187  \\\n",
      "0              96.240225          44.370493          92.490606   \n",
      "1             152.605688          70.357168         146.660012   \n",
      "2             155.320989          71.609027         149.269522   \n",
      "3              89.760888          41.383267          86.263711   \n",
      "4             136.606181          62.980772         131.283862   \n",
      "...                  ...                ...                ...   \n",
      "1494          123.582270          60.878890         132.604454   \n",
      "1495          125.056675          65.161668         113.900752   \n",
      "1496          143.537284          61.538381         153.068401   \n",
      "1497          133.870249          58.142396         130.036721   \n",
      "1498          125.262158          52.407681         127.618632   \n",
      "\n",
      "      51.74548074388351  70.94138489080802  146.05579242225184  \\\n",
      "0             38.746065          53.119605          109.363892   \n",
      "1             61.438654          84.230412          173.415555   \n",
      "2             62.531827          85.729117          176.501124   \n",
      "3             36.137500          49.543347          102.001009   \n",
      "4             54.997294          75.399516          155.234297   \n",
      "...                 ...                ...                 ...   \n",
      "1494          50.364303          64.814536          151.399639   \n",
      "1495          55.191095          64.646527          128.312405   \n",
      "1496          56.491732          75.023382          155.233330   \n",
      "1497          54.023561          75.286528          140.604006   \n",
      "1498          49.770773          76.869654          161.807403   \n",
      "\n",
      "      83.46045281271535  ...  119.22751544409022.1  75.46045281271533.3  \\\n",
      "0             62.493653  ...             86.099971            54.493653   \n",
      "1             99.094603  ...            143.929472            91.094603   \n",
      "2            100.857785  ...            146.715300            92.857785   \n",
      "3             58.286291  ...             79.452340            50.286291   \n",
      "4             88.705312  ...            127.514394            80.705312   \n",
      "...                 ...  ...                   ...                  ...   \n",
      "1494          83.490475  ...            137.369130            80.431789   \n",
      "1495          79.987625  ...            105.283001            82.767544   \n",
      "1496          88.213839  ...            142.178266            87.802081   \n",
      "1497          73.680902  ...            124.548565            70.530184   \n",
      "1498          90.833218  ...            123.218064            82.663633   \n",
      "\n",
      "      0.163  122.24593355659883.1  67.9144075314438.3  49.04929432826497.1  \\\n",
      "0         0             88.279717           49.044287            35.420874   \n",
      "1         0            147.573256           81.985142            59.211492   \n",
      "2         0            150.429612           83.572007            60.357560   \n",
      "3         0             81.463791           45.257662            32.686089   \n",
      "4         0            130.742606           72.634781            52.458453   \n",
      "...     ...                   ...                 ...                  ...   \n",
      "1494      0            126.811717           70.233824            53.435112   \n",
      "1495      0            124.968589           61.291457            53.878428   \n",
      "1496      0            134.161363           82.170146            52.356536   \n",
      "1497      0            132.826375           61.829803            48.018066   \n",
      "1498      0            118.280322           59.692524            42.836729   \n",
      "\n",
      "      0.164  0.165  0.166  0.167  \n",
      "0         0      0      0      0  \n",
      "1         0      0      0      0  \n",
      "2         0      0      0      0  \n",
      "3         0      0      0      0  \n",
      "4         0      0      0      0  \n",
      "...     ...    ...    ...    ...  \n",
      "1494      0      0      0      0  \n",
      "1495      0      0      0      0  \n",
      "1496      0      0      0      0  \n",
      "1497      0      0      0      0  \n",
      "1498      0      0      0      0  \n",
      "\n",
      "[1499 rows x 576 columns]>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "##### data set 24 Bus 8 Prd\n",
    "\n",
    "dfXoF_24 = pd.read_csv(\"demand24Bus24Prd_outofSample.txt\")\n",
    "\n",
    "print(dfXoF_24.info)\n",
    "\n",
    "xoF = dfXoF_24.to_numpy()\n",
    "#x = np.delete(x,0,1) #delete column one sample number\n",
    "xoF = xoF/100\n",
    "\n",
    "# Explicitly set apart 20% for validation data that we never train over.\n",
    "split_at = 100\n",
    "(x_oF, x_restoF) = xoF[:split_at], xoF[split_at:]\n",
    "\n",
    "print(len(x_oF))\n",
    "\n",
    "x_oF = x_oF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is:  0.01\n"
     ]
    }
   ],
   "source": [
    "i = 0.01\n",
    "print (\"learning rate is: \",i)\n",
    "w = models[i][\"w\"]\n",
    "b = models[i][\"b\"]\n",
    "A_prediction_oF = predict(w, b, x_oF)\n",
    "A_prediction_oF = A_prediction_oF.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_prediction_round_oF = np.around(A_prediction_oF, decimals=6)\n",
    "#A_prediction_test_round = A_prediction_test_round.T\n",
    "with open(\"probabilities24Bus24PrdSample4Ampl_outofSample.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(A_prediction_round_oF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_round_oF = np.around(x_oF, decimals=4)\n",
    "x_round_oF = x_round_oF.T\n",
    "with open(\"demand24Bus24PrdSample4Ampl_outofSample.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(x_round_oF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.73286795 1.25602435 0.97820297 0.8064884  0.69327368 0.61435643\n",
      "  0.55680057 0.51326384 0.47933965 0.45225177 0.43017706 0.41187523\n",
      "  0.39647648 0.38335472 0.37204884 0.36221249 0.3535808  0.3459481\n",
      "  0.33915238 0.33306446 0.32758011 0.3226144  0.31809746 0.31397129\n",
      "  0.31018742 0.30670498 0.30348932 0.30051086 0.29774422 0.29516749\n",
      "  0.29276166 0.29051017 0.28839852 0.28641395 0.28454522 0.28278237\n",
      "  0.28111654 0.27953984 0.27804518 0.27662625 0.27527732 0.27399326\n",
      "  0.27276941 0.27160156 0.27048585 0.26941881 0.26839725 0.26741824\n",
      "  0.26647912 0.26557743 0.26471091 0.2638775  0.26307526 0.26230243\n",
      "  0.26155737 0.26083855 0.26014457 0.25947411 0.25882594 0.25819894\n",
      "  0.25759204 0.25700424 0.25643462 0.25588231 0.25534649 0.2548264\n",
      "  0.25432133 0.25383059 0.25335356 0.25288963 0.25243824 0.25199887\n",
      "  0.251571   0.25115416 0.25074791 0.25035181 0.24996547 0.24958851\n",
      "  0.24922056 0.24886129 0.24851035 0.24816745 0.24783229 0.24750459\n",
      "  0.24718408 0.24687051 0.24656363 0.24626322 0.24596905 0.2456809\n",
      "  0.24539859 0.24512192 0.2448507  0.24458475 0.24432391 0.24406802\n",
      "  0.24381692 0.24357046 0.2433285  0.24309091 0.24285755 0.24262829\n",
      "  0.24240303 0.24218163 0.24196398 0.24174999 0.24153955 0.24133255\n",
      "  0.2411289  0.24092852 0.2407313  0.24053717 0.24034604 0.24015783\n",
      "  0.23997247 0.23978988 0.23960998 0.23943272 0.23925802 0.23908582\n",
      "  0.23891606 0.23874867 0.2385836  0.23842079 0.23826019 0.23810174\n",
      "  0.2379454  0.2377911  0.23763881 0.23748848 0.23734007 0.23719352\n",
      "  0.2370488  0.23690587 0.23676468 0.2366252  0.23648739 0.23635122\n",
      "  0.23621664 0.23608363 0.23595214 0.23582216 0.23569364 0.23556656\n",
      "  0.23544088 0.23531659 0.23519364 0.23507201 0.23495168 0.23483261\n",
      "  0.2347148  0.2345982  0.23448279 0.23436856 0.23425548 0.23414353\n",
      "  0.23403268 0.23392292 0.23381422 0.23370657 0.23359994 0.23349432\n",
      "  0.23338969 0.23328602 0.23318331 0.23308154 0.23298068 0.23288073\n",
      "  0.23278166 0.23268346 0.23258612 0.23248962 0.23239395 0.23229909\n",
      "  0.23220502 0.23211174 0.23201924 0.23192749 0.23183649 0.23174622\n",
      "  0.23165667 0.23156783 0.2314797  0.23139224 0.23130547 0.23121936\n",
      "  0.23113391 0.2310491  0.23096492 0.23088137 0.23079843 0.2307161\n",
      "  0.23063437 0.23055322 0.23047265 0.23039265 0.23031321 0.23023433\n",
      "  0.23015599 0.23007818 0.2300009  0.22992415 0.2298479  0.22977217\n",
      "  0.22969693 0.22962218 0.22954792 0.22947413 0.22940082 0.22932797\n",
      "  0.22925557 0.22918363 0.22911214 0.22904108 0.22897046 0.22890026\n",
      "  0.22883049 0.22876113 0.22869218 0.22862364 0.22855549 0.22848774\n",
      "  0.22842038 0.22835341 0.22828681 0.22822058 0.22815473 0.22808924\n",
      "  0.22802411 0.22795934 0.22789492 0.22783084 0.22776711 0.22770371\n",
      "  0.22764065 0.22757792 0.22751551 0.22745343 0.22739166 0.22733021\n",
      "  0.22726907 0.22720823 0.2271477  0.22708747 0.22702753 0.22696788\n",
      "  0.22690853 0.22684946 0.22679067 0.22673216 0.22667393 0.22661597\n",
      "  0.22655828 0.22650085 0.22644369 0.22638679 0.22633015 0.22627376\n",
      "  0.22621763 0.22616174 0.2261061  0.22605071 0.22599555 0.22594064\n",
      "  0.22588596 0.22583151 0.2257773  0.22572331 0.22566955 0.22561601\n",
      "  0.2255627  0.2255096  0.22545672 0.22540406 0.22535161 0.22529936\n",
      "  0.22524733 0.2251955  0.22514388 0.22509246 0.22504123 0.22499021\n",
      "  0.22493938 0.22488875 0.2248383  0.22478805 0.22473799 0.22468811\n",
      "  0.22463841 0.2245889  0.22453957 0.22449042 0.22444145 0.22439265\n",
      "  0.22434403 0.22429558 0.2242473  0.22419919 0.22415125 0.22410347\n",
      "  0.22405586 0.22400842 0.22396113 0.223914   0.22386704 0.22382023\n",
      "  0.22377357 0.22372707 0.22368073 0.22363453 0.22358849 0.2235426\n",
      "  0.22349685 0.22345125 0.22340579 0.22336048 0.22331531 0.22327029\n",
      "  0.2232254  0.22318065 0.22313604 0.22309157 0.22304723 0.22300303\n",
      "  0.22295896 0.22291502 0.22287121 0.22282754 0.22278399 0.22274057\n",
      "  0.22269728 0.22265411 0.22261107 0.22256815 0.22252535 0.22248268\n",
      "  0.22244012 0.22239769 0.22235537 0.22231318 0.2222711  0.22222913\n",
      "  0.22218728 0.22214555 0.22210393 0.22206242 0.22202102 0.22197974\n",
      "  0.22193856 0.22189749 0.22185653 0.22181568 0.22177494 0.2217343\n",
      "  0.22169376 0.22165333 0.22161301 0.22157278 0.22153266 0.22149264\n",
      "  0.22145272 0.2214129  0.22137318 0.22133355 0.22129403 0.2212546\n",
      "  0.22121527 0.22117603 0.22113689 0.22109784 0.22105888 0.22102002\n",
      "  0.22098125 0.22094257 0.22090399 0.22086549 0.22082708 0.22078876\n",
      "  0.22075053 0.22071239 0.22067433 0.22063637 0.22059848 0.22056069\n",
      "  0.22052298 0.22048535 0.2204478  0.22041034 0.22037296 0.22033567\n",
      "  0.22029845 0.22026132 0.22022427 0.22018729 0.2201504  0.22011359\n",
      "  0.22007685 0.22004019 0.22000361 0.21996711 0.21993068 0.21989433\n",
      "  0.21985805 0.21982185 0.21978573 0.21974967 0.2197137  0.21967779\n",
      "  0.21964196 0.2196062  0.21957051 0.21953489 0.21949935 0.21946387\n",
      "  0.21942847 0.21939313 0.21935786 0.21932267 0.21928754 0.21925248\n",
      "  0.21921748 0.21918256 0.2191477  0.2191129  0.21907818 0.21904352\n",
      "  0.21900892 0.21897439 0.21893992 0.21890552 0.21887118 0.21883691\n",
      "  0.2188027  0.21876855 0.21873446 0.21870044 0.21866647 0.21863257\n",
      "  0.21859873 0.21856495 0.21853123 0.21849757 0.21846397 0.21843043\n",
      "  0.21839695 0.21836353 0.21833017 0.21829686 0.21826361 0.21823042\n",
      "  0.21819729 0.21816421 0.21813119 0.21809822 0.21806532 0.21803246\n",
      "  0.21799967 0.21796692 0.21793424 0.2179016  0.21786903 0.2178365\n",
      "  0.21780403 0.21777161 0.21773925 0.21770694 0.21767468 0.21764247\n",
      "  0.21761032 0.21757821 0.21754616 0.21751416 0.21748221 0.21745031\n",
      "  0.21741847 0.21738667 0.21735492 0.21732322 0.21729158 0.21725998\n",
      "  0.21722843 0.21719693 0.21716548 0.21713407 0.21710272 0.21707141\n",
      "  0.21704015 0.21700893 0.21697777 0.21694665 0.21691558 0.21688455\n",
      "  0.21685358 0.21682264 0.21679176 0.21676091 0.21673012 0.21669937\n",
      "  0.21666866 0.216638   0.21660739 0.21657682 0.21654629 0.21651581\n",
      "  0.21648537 0.21645497 0.21642462 0.21639431 0.21636405 0.21633383\n",
      "  0.21630365 0.21627351 0.21624341 0.21621336 0.21618335 0.21615338\n",
      "  0.21612346 0.21609357 0.21606373 0.21603392 0.21600416 0.21597444\n",
      "  0.21594476 0.21591512 0.21588552 0.21585596 0.21582643 0.21579695\n",
      "  0.21576751 0.21573811 0.21570875 0.21567943 0.21565014 0.21562089\n",
      "  0.21559169 0.21556252 0.21553339 0.2155043  0.21547524 0.21544623\n",
      "  0.21541725 0.21538831 0.2153594  0.21533053 0.21530171 0.21527291\n",
      "  0.21524416 0.21521544 0.21518675 0.21515811 0.2151295  0.21510092\n",
      "  0.21507239 0.21504388 0.21501542 0.21498699 0.21495859 0.21493023\n",
      "  0.2149019  0.21487361 0.21484536 0.21481714 0.21478895 0.2147608\n",
      "  0.21473268 0.2147046  0.21467655 0.21464854 0.21462056 0.21459261\n",
      "  0.21456469 0.21453681 0.21450897 0.21448115 0.21445337 0.21442562\n",
      "  0.21439791 0.21437023 0.21434258 0.21431496 0.21428738 0.21425982\n",
      "  0.2142323  0.21420482 0.21417736 0.21414994 0.21412254 0.21409518\n",
      "  0.21406785 0.21404056 0.21401329 0.21398605 0.21395885 0.21393168\n",
      "  0.21390453 0.21387742 0.21385034 0.21382329 0.21379627 0.21376928\n",
      "  0.21374232 0.21371539 0.21368849 0.21366162 0.21363478 0.21360797\n",
      "  0.21358119 0.21355444 0.21352772 0.21350103 0.21347437 0.21344774\n",
      "  0.21342113 0.21339456 0.21336801 0.21334149 0.213315   0.21328854\n",
      "  0.21326211 0.21323571 0.21320933 0.21318299 0.21315667 0.21313038\n",
      "  0.21310412 0.21307788 0.21305168 0.2130255  0.21299934 0.21297322\n",
      "  0.21294712 0.21292106 0.21289501 0.212869   0.21284301 0.21281705\n",
      "  0.21279112 0.21276521 0.21273933 0.21271348 0.21268766 0.21266186\n",
      "  0.21263608 0.21261034 0.21258462 0.21255892 0.21253325 0.21250761\n",
      "  0.212482   0.21245641 0.21243084 0.21240531 0.21237979 0.21235431\n",
      "  0.21232885 0.21230341 0.212278   0.21225262 0.21222726 0.21220192\n",
      "  0.21217661 0.21215133 0.21212607 0.21210084 0.21207563 0.21205044\n",
      "  0.21202528 0.21200015 0.21197504 0.21194995 0.21192489 0.21189985\n",
      "  0.21187484 0.21184985 0.21182489 0.21179995 0.21177503 0.21175014\n",
      "  0.21172527 0.21170043 0.21167561 0.21165081 0.21162604 0.21160129\n",
      "  0.21157656 0.21155186 0.21152718 0.21150252 0.21147789 0.21145328\n",
      "  0.2114287  0.21140413 0.21137959 0.21135508 0.21133058 0.21130611\n",
      "  0.21128166 0.21125724 0.21123284 0.21120846 0.2111841  0.21115976\n",
      "  0.21113545 0.21111116 0.21108689 0.21106265 0.21103842 0.21101422\n",
      "  0.21099004 0.21096589 0.21094175 0.21091764 0.21089355 0.21086948\n",
      "  0.21084543 0.21082141 0.2107974  0.21077342 0.21074946 0.21072552\n",
      "  0.2107016  0.21067771 0.21065383 0.21062998 0.21060615 0.21058234\n",
      "  0.21055855 0.21053478 0.21051103 0.21048731 0.2104636  0.21043992\n",
      "  0.21041625 0.21039261 0.21036899 0.21034539 0.21032181 0.21029825\n",
      "  0.21027471 0.21025119 0.21022769 0.21020421 0.21018076 0.21015732\n",
      "  0.2101339  0.21011051 0.21008713 0.21006377 0.21004044 0.21001712\n",
      "  0.20999383 0.20997055 0.20994729 0.20992406 0.20990084 0.20987765\n",
      "  0.20985447 0.20983131 0.20980818 0.20978506 0.20976196 0.20973888\n",
      "  0.20971582 0.20969278 0.20966976 0.20964676 0.20962378 0.20960082\n",
      "  0.20957788 0.20955495 0.20953205 0.20950916 0.2094863  0.20946345\n",
      "  0.20944062 0.20941781 0.20939502 0.20937225 0.2093495  0.20932677\n",
      "  0.20930405 0.20928136 0.20925868 0.20923602 0.20921338 0.20919076\n",
      "  0.20916816 0.20914557 0.209123   0.20910046 0.20907793 0.20905542\n",
      "  0.20903292 0.20901045 0.20898799 0.20896556 0.20894314 0.20892074\n",
      "  0.20889835 0.20887599 0.20885364 0.20883131 0.208809   0.2087867\n",
      "  0.20876443 0.20874217 0.20871993 0.20869771 0.2086755  0.20865332\n",
      "  0.20863115 0.208609   0.20858686 0.20856475 0.20854265 0.20852057\n",
      "  0.2084985  0.20847646 0.20845443 0.20843241 0.20841042 0.20838844\n",
      "  0.20836648 0.20834454 0.20832261 0.20830071 0.20827881 0.20825694\n",
      "  0.20823508 0.20821324 0.20819142 0.20816961 0.20814783 0.20812605\n",
      "  0.2081043  0.20808256 0.20806084 0.20803913 0.20801744 0.20799577\n",
      "  0.20797412 0.20795248 0.20793086 0.20790925 0.20788766 0.20786609\n",
      "  0.20784454 0.207823   0.20780148 0.20777997 0.20775848 0.20773701\n",
      "  0.20771555 0.20769411 0.20767268 0.20765128 0.20762988 0.20760851\n",
      "  0.20758715 0.20756581 0.20754448 0.20752317 0.20750187 0.20748059\n",
      "  0.20745933 0.20743808 0.20741685 0.20739563 0.20737443 0.20735325\n",
      "  0.20733208 0.20731093 0.20728979 0.20726867 0.20724757 0.20722648\n",
      "  0.2072054  0.20718435 0.2071633  0.20714228 0.20712126 0.20710027\n",
      "  0.20707929 0.20705832 0.20703737 0.20701644 0.20699552 0.20697462\n",
      "  0.20695373 0.20693286 0.206912   0.20689116 0.20687033 0.20684952\n",
      "  0.20682872 0.20680794 0.20678717 0.20676642 0.20674569 0.20672497\n",
      "  0.20670426 0.20668357 0.20666289 0.20664223 0.20662159 0.20660095\n",
      "  0.20658034 0.20655974 0.20653915 0.20651858 0.20649802 0.20647748\n",
      "  0.20645695 0.20643644 0.20641594 0.20639546 0.20637499 0.20635453\n",
      "  0.20633409 0.20631367 0.20629326 0.20627286 0.20625248 0.20623212\n",
      "  0.20621176 0.20619143 0.2061711  0.20615079 0.2061305  0.20611022\n",
      "  0.20608995 0.2060697  0.20604946 0.20602924 0.20600903 0.20598884\n",
      "  0.20596866 0.20594849 0.20592834 0.2059082  0.20588807 0.20586796\n",
      "  0.20584787 0.20582779 0.20580772 0.20578767 0.20576763 0.2057476\n",
      "  0.20572759 0.20570759 0.20568761 0.20566764 0.20564768 0.20562774\n",
      "  0.20560781 0.2055879  0.205568   0.20554811 0.20552823 0.20550837\n",
      "  0.20548853 0.2054687  0.20544888 0.20542907 0.20540928 0.2053895\n",
      "  0.20536974 0.20534999 0.20533025 0.20531053 0.20529082 0.20527112\n",
      "  0.20525144 0.20523177 0.20521211 0.20519247 0.20517284 0.20515322\n",
      "  0.20513362 0.20511403 0.20509446 0.20507489 0.20505534 0.20503581\n",
      "  0.20501628 0.20499678 0.20497728 0.2049578  0.20493832 0.20491887\n",
      "  0.20489942 0.20487999 0.20486058 0.20484117 0.20482178 0.2048024\n",
      "  0.20478303 0.20476368 0.20474434 0.20472502]\n",
      " [1.73286795 0.65790305 0.47983042 0.4063921  0.36608253 0.34054065\n",
      "  0.32287267 0.30990221 0.29996092 0.29208807 0.2856912  0.28038493\n",
      "  0.27590767 0.27207559 0.26875562 0.26584906 0.26328115 0.26099415\n",
      "  0.25894283 0.25709116 0.25541014 0.25387616 0.25246975 0.25117477\n",
      "  0.24997769 0.24886708 0.24783325 0.24686789 0.24596387 0.24511499\n",
      "  0.2443159  0.24356189 0.24284884 0.24217313 0.24153153 0.2409212\n",
      "  0.2403396  0.23978445 0.23925371 0.23874556 0.23825834 0.23779055\n",
      "  0.23734084 0.23690799 0.23649087 0.23608846 0.23569982 0.2353241\n",
      "  0.23496052 0.23460834 0.23426691 0.2339356  0.23361385 0.23330114\n",
      "  0.23299698 0.23270091 0.23241252 0.23213141 0.23185721 0.2315896\n",
      "  0.23132824 0.23107285 0.23082314 0.23057885 0.23033974 0.23010558\n",
      "  0.22987615 0.22965125 0.22943068 0.22921427 0.22900185 0.22879325\n",
      "  0.22858832 0.22838692 0.22818891 0.22799416 0.22780256 0.22761397\n",
      "  0.2274283  0.22724544 0.22706529 0.22688776 0.22671275 0.22654017\n",
      "  0.22636996 0.22620202 0.22603629 0.22587269 0.22571116 0.22555163\n",
      "  0.22539404 0.22523833 0.22508444 0.22493232 0.22478191 0.22463317\n",
      "  0.22448605 0.22434051 0.22419649 0.22405396 0.22391288 0.2237732\n",
      "  0.22363489 0.22349791 0.22336224 0.22322783 0.22309465 0.22296267\n",
      "  0.22283187 0.2227022  0.22257366 0.2224462  0.22231981 0.22219445\n",
      "  0.22207011 0.22194676 0.22182437 0.22170294 0.22158243 0.22146282\n",
      "  0.2213441  0.22122624 0.22110924 0.22099306 0.2208777  0.22076313\n",
      "  0.22064935 0.22053633 0.22042406 0.22031252 0.2202017  0.22009159\n",
      "  0.21998217 0.21987344 0.21976537 0.21965795 0.21955118 0.21944504\n",
      "  0.21933952 0.21923461 0.2191303  0.21902657 0.21892343 0.21882085\n",
      "  0.21871883 0.21861736 0.21851643 0.21841603 0.21831615 0.21821679\n",
      "  0.21811794 0.21801958 0.21792171 0.21782433 0.21772742 0.21763099\n",
      "  0.21753501 0.21743949 0.21734441 0.21724978 0.21715559 0.21706182\n",
      "  0.21696848 0.21687555 0.21678303 0.21669092 0.21659922 0.2165079\n",
      "  0.21641698 0.21632644 0.21623628 0.21614649 0.21605708 0.21596803\n",
      "  0.21587934 0.21579101 0.21570302 0.21561539 0.2155281  0.21544115\n",
      "  0.21535453 0.21526825 0.21518229 0.21509666 0.21501134 0.21492634\n",
      "  0.21484166 0.21475728 0.21467321 0.21458944 0.21450598 0.2144228\n",
      "  0.21433992 0.21425733 0.21417503 0.21409301 0.21401127 0.21392981\n",
      "  0.21384862 0.21376771 0.21368707 0.21360669 0.21352658 0.21344672\n",
      "  0.21336713 0.2132878  0.21320872 0.21312989 0.21305131 0.21297298\n",
      "  0.21289489 0.21281705 0.21273945 0.21266208 0.21258495 0.21250806\n",
      "  0.2124314  0.21235497 0.21227877 0.21220279 0.21212704 0.21205151\n",
      "  0.2119762  0.21190112 0.21182624 0.21175159 0.21167715 0.21160292\n",
      "  0.2115289  0.21145508 0.21138148 0.21130808 0.21123489 0.2111619\n",
      "  0.2110891  0.21101651 0.21094412 0.21087192 0.21079992 0.21072811\n",
      "  0.21065649 0.21058506 0.21051383 0.21044278 0.21037192 0.21030124\n",
      "  0.21023075 0.21016044 0.21009031 0.21002036 0.20995059 0.209881\n",
      "  0.20981159 0.20974235 0.20967329 0.2096044  0.20953569 0.20946714\n",
      "  0.20939876 0.20933056 0.20926252 0.20919465 0.20912694 0.2090594\n",
      "  0.20899202 0.20892481 0.20885776 0.20879087 0.20872414 0.20865757\n",
      "  0.20859115 0.2085249  0.2084588  0.20839285 0.20832706 0.20826143\n",
      "  0.20819594 0.20813061 0.20806543 0.2080004  0.20793552 0.20787079\n",
      "  0.20780621 0.20774177 0.20767748 0.20761334 0.20754934 0.20748548\n",
      "  0.20742177 0.2073582  0.20729477 0.20723148 0.20716833 0.20710532\n",
      "  0.20704245 0.20697972 0.20691713 0.20685467 0.20679235 0.20673017\n",
      "  0.20666812 0.2066062  0.20654442 0.20648277 0.20642125 0.20635987\n",
      "  0.20629861 0.20623749 0.2061765  0.20611563 0.20605489 0.20599428\n",
      "  0.2059338  0.20587345 0.20581322 0.20575312 0.20569314 0.20563329\n",
      "  0.20557356 0.20551395 0.20545447 0.20539511 0.20533587 0.20527676\n",
      "  0.20521776 0.20515889 0.20510013 0.20504149 0.20498298 0.20492458\n",
      "  0.2048663  0.20480813 0.20475008 0.20469215 0.20463434 0.20457664\n",
      "  0.20451905 0.20446158 0.20440423 0.20434698 0.20428986 0.20423284\n",
      "  0.20417593 0.20411914 0.20406246 0.20400589 0.20394943 0.20389308\n",
      "  0.20383684 0.20378071 0.20372469 0.20366877 0.20361297 0.20355727\n",
      "  0.20350168 0.20344619 0.20339081 0.20333554 0.20328038 0.20322532\n",
      "  0.20317036 0.20311551 0.20306076 0.20300612 0.20295158 0.20289714\n",
      "  0.2028428  0.20278857 0.20273444 0.20268041 0.20262648 0.20257265\n",
      "  0.20251893 0.2024653  0.20241177 0.20235835 0.20230502 0.20225179\n",
      "  0.20219866 0.20214562 0.20209269 0.20203985 0.20198711 0.20193446\n",
      "  0.20188192 0.20182947 0.20177711 0.20172485 0.20167268 0.20162061\n",
      "  0.20156864 0.20151676 0.20146497 0.20141328 0.20136168 0.20131017\n",
      "  0.20125875 0.20120743 0.2011562  0.20110506 0.20105402 0.20100306\n",
      "  0.2009522  0.20090143 0.20085074 0.20080015 0.20074965 0.20069924\n",
      "  0.20064891 0.20059868 0.20054853 0.20049847 0.2004485  0.20039862\n",
      "  0.20034883 0.20029912 0.20024951 0.20019997 0.20015053 0.20010117\n",
      "  0.2000519  0.20000271 0.19995361 0.1999046  0.19985567 0.19980682\n",
      "  0.19975806 0.19970938 0.19966079 0.19961228 0.19956386 0.19951552\n",
      "  0.19946726 0.19941909 0.19937099 0.19932299 0.19927506 0.19922721\n",
      "  0.19917945 0.19913177 0.19908417 0.19903665 0.19898921 0.19894185\n",
      "  0.19889458 0.19884738 0.19880026 0.19875323 0.19870627 0.19865939\n",
      "  0.19861259 0.19856587 0.19851923 0.19847267 0.19842618 0.19837978\n",
      "  0.19833345 0.1982872  0.19824102 0.19819493 0.19814891 0.19810297\n",
      "  0.1980571  0.19801131 0.1979656  0.19791996 0.1978744  0.19782891\n",
      "  0.1977835  0.19773817 0.19769291 0.19764772 0.19760261 0.19755758\n",
      "  0.19751262 0.19746773 0.19742291 0.19737817 0.19733351 0.19728891\n",
      "  0.19724439 0.19719995 0.19715557 0.19711127 0.19706704 0.19702288\n",
      "  0.1969788  0.19693478 0.19689084 0.19684697 0.19680317 0.19675944\n",
      "  0.19671579 0.1966722  0.19662869 0.19658524 0.19654187 0.19649856\n",
      "  0.19645533 0.19641216 0.19636906 0.19632604 0.19628308 0.19624019\n",
      "  0.19619737 0.19615462 0.19611194 0.19606933 0.19602678 0.1959843\n",
      "  0.19594189 0.19589955 0.19585728 0.19581507 0.19577293 0.19573086\n",
      "  0.19568885 0.19564691 0.19560504 0.19556324 0.1955215  0.19547982\n",
      "  0.19543822 0.19539667 0.1953552  0.19531379 0.19527244 0.19523116\n",
      "  0.19518995 0.1951488  0.19510771 0.19506669 0.19502573 0.19498484\n",
      "  0.19494401 0.19490325 0.19486255 0.19482191 0.19478134 0.19474083\n",
      "  0.19470038 0.19466    0.19461968 0.19457942 0.19453923 0.1944991\n",
      "  0.19445903 0.19441902 0.19437907 0.19433919 0.19429937 0.19425961\n",
      "  0.19421991 0.19418027 0.1941407  0.19410118 0.19406173 0.19402234\n",
      "  0.19398301 0.19394373 0.19390452 0.19386537 0.19382628 0.19378725\n",
      "  0.19374828 0.19370937 0.19367052 0.19363173 0.193593   0.19355432\n",
      "  0.19351571 0.19347715 0.19343866 0.19340022 0.19336184 0.19332352\n",
      "  0.19328526 0.19324706 0.19320891 0.19317083 0.1931328  0.19309482\n",
      "  0.19305691 0.19301905 0.19298125 0.19294351 0.19290583 0.1928682\n",
      "  0.19283063 0.19279311 0.19275566 0.19271825 0.19268091 0.19264362\n",
      "  0.19260639 0.19256921 0.19253209 0.19249503 0.19245802 0.19242106\n",
      "  0.19238416 0.19234732 0.19231053 0.1922738  0.19223712 0.1922005\n",
      "  0.19216393 0.19212742 0.19209096 0.19205455 0.1920182  0.19198191\n",
      "  0.19194567 0.19190948 0.19187334 0.19183726 0.19180123 0.19176526\n",
      "  0.19172934 0.19169347 0.19165766 0.1916219  0.19158619 0.19155053\n",
      "  0.19151493 0.19147938 0.19144388 0.19140844 0.19137304 0.1913377\n",
      "  0.19130242 0.19126718 0.19123199 0.19119686 0.19116178 0.19112675\n",
      "  0.19109177 0.19105684 0.19102197 0.19098714 0.19095237 0.19091764\n",
      "  0.19088297 0.19084835 0.19081378 0.19077926 0.19074479 0.19071037\n",
      "  0.190676   0.19064168 0.19060741 0.19057319 0.19053902 0.1905049\n",
      "  0.19047083 0.19043681 0.19040283 0.19036891 0.19033504 0.19030121\n",
      "  0.19026744 0.19023371 0.19020003 0.1901664  0.19013282 0.19009929\n",
      "  0.19006581 0.19003237 0.18999898 0.18996565 0.18993235 0.18989911\n",
      "  0.18986592 0.18983277 0.18979967 0.18976662 0.18973361 0.18970065\n",
      "  0.18966774 0.18963488 0.18960206 0.18956929 0.18953657 0.1895039\n",
      "  0.18947127 0.18943869 0.18940615 0.18937366 0.18934122 0.18930882\n",
      "  0.18927647 0.18924417 0.18921191 0.1891797  0.18914753 0.18911541\n",
      "  0.18908333 0.1890513  0.18901932 0.18898738 0.18895549 0.18892364\n",
      "  0.18889184 0.18886008 0.18882836 0.1887967  0.18876507 0.18873349\n",
      "  0.18870196 0.18867047 0.18863902 0.18860762 0.18857626 0.18854495\n",
      "  0.18851368 0.18848246 0.18845128 0.18842014 0.18838905 0.188358\n",
      "  0.18832699 0.18829603 0.18826511 0.18823423 0.1882034  0.18817261\n",
      "  0.18814186 0.18811116 0.1880805  0.18804988 0.18801931 0.18798878\n",
      "  0.18795829 0.18792784 0.18789743 0.18786707 0.18783675 0.18780647\n",
      "  0.18777624 0.18774604 0.18771589 0.18768578 0.18765572 0.18762569\n",
      "  0.1875957  0.18756576 0.18753586 0.187506   0.18747618 0.1874464\n",
      "  0.18741667 0.18738697 0.18735732 0.1873277  0.18729813 0.1872686\n",
      "  0.18723911 0.18720966 0.18718025 0.18715088 0.18712155 0.18709226\n",
      "  0.18706301 0.1870338  0.18700464 0.18697551 0.18694642 0.18691737\n",
      "  0.18688836 0.1868594  0.18683047 0.18680158 0.18677273 0.18674392\n",
      "  0.18671515 0.18668642 0.18665772 0.18662907 0.18660046 0.18657188\n",
      "  0.18654335 0.18651485 0.18648639 0.18645797 0.18642959 0.18640125\n",
      "  0.18637295 0.18634468 0.18631645 0.18628826 0.18626011 0.186232\n",
      "  0.18620393 0.18617589 0.1861479  0.18611994 0.18609201 0.18606413\n",
      "  0.18603628 0.18600847 0.1859807  0.18595297 0.18592527 0.18589761\n",
      "  0.18586999 0.18584241 0.18581486 0.18578735 0.18575988 0.18573244\n",
      "  0.18570504 0.18567768 0.18565035 0.18562306 0.18559581 0.18556859\n",
      "  0.18554141 0.18551427 0.18548716 0.18546009 0.18543306 0.18540606\n",
      "  0.1853791  0.18535218 0.18532529 0.18529843 0.18527161 0.18524483\n",
      "  0.18521809 0.18519137 0.1851647  0.18513806 0.18511146 0.18508489\n",
      "  0.18505835 0.18503186 0.18500539 0.18497897 0.18495257 0.18492622\n",
      "  0.18489989 0.18487361 0.18484735 0.18482113 0.18479495 0.1847688\n",
      "  0.18474269 0.18471661 0.18469056 0.18466455 0.18463858 0.18461264\n",
      "  0.18458673 0.18456086 0.18453502 0.18450921 0.18448344 0.1844577\n",
      "  0.184432   0.18440633 0.18438069 0.18435509 0.18432952 0.18430399\n",
      "  0.18427849 0.18425302 0.18422759 0.18420219 0.18417682 0.18415148\n",
      "  0.18412618 0.18410091 0.18407568 0.18405048 0.18402531 0.18400017\n",
      "  0.18397507 0.18395    0.18392496 0.18389996 0.18387498 0.18385004\n",
      "  0.18382514 0.18380026 0.18377542 0.18375061 0.18372583 0.18370109\n",
      "  0.18367637 0.18365169 0.18362704 0.18360242 0.18357784 0.18355329\n",
      "  0.18352876 0.18350427 0.18347982 0.18345539 0.183431   0.18340663\n",
      "  0.1833823  0.183358   0.18333373 0.18330949 0.18328529 0.18326111\n",
      "  0.18323697 0.18321286 0.18318878 0.18316472 0.18314071 0.18311672\n",
      "  0.18309276 0.18306883 0.18304494 0.18302107 0.18299724 0.18297343\n",
      "  0.18294966 0.18292592 0.1829022  0.18287852 0.18285487 0.18283125\n",
      "  0.18280766 0.1827841  0.18276057 0.18273706 0.18271359 0.18269015\n",
      "  0.18266674 0.18264336 0.18262001 0.18259669 0.1825734  0.18255014\n",
      "  0.1825269  0.1825037  0.18248053 0.18245739 0.18243427 0.18241119\n",
      "  0.18238813 0.18236511 0.18234211 0.18231914 0.1822962  0.18227329\n",
      "  0.18225041 0.18222756 0.18220474 0.18218195 0.18215918 0.18213645\n",
      "  0.18211374 0.18209106 0.18206841 0.18204579 0.1820232  0.18200064\n",
      "  0.1819781  0.1819556  0.18193312 0.18191067 0.18188825 0.18186585\n",
      "  0.18184349 0.18182115 0.18179884 0.18177656 0.18175431 0.18173208\n",
      "  0.18170989 0.18168772 0.18166558 0.18164346 0.18162138 0.18159932\n",
      "  0.18157729 0.18155528 0.18153331 0.18151136 0.18148944 0.18146755\n",
      "  0.18144568 0.18142384 0.18140203 0.18138025 0.18135849 0.18133676\n",
      "  0.18131506 0.18129339 0.18127174 0.18125012 0.18122852 0.18120696\n",
      "  0.18118542 0.1811639  0.18114241 0.18112095]\n",
      " [1.73286795 0.39080155 0.33795521 0.31130075 0.29498566 0.28388627\n",
      "  0.27580514 0.26963467 0.26475337 0.26078445 0.25748575 0.25469428\n",
      "  0.2522962  0.25020955 0.24837375 0.24674305 0.24528226 0.24396382\n",
      "  0.24276587 0.24167083 0.2406644  0.23973483 0.23887236 0.23806885\n",
      "  0.23731742 0.23661224 0.2359483  0.23532134 0.23472763 0.23416395\n",
      "  0.2336275  0.2331158  0.23262668 0.23215822 0.2317087  0.23127662\n",
      "  0.23086061 0.23045945 0.23007205 0.22969742 0.22933467 0.22898299\n",
      "  0.22864164 0.22830996 0.22798733 0.2276732  0.22736706 0.22706843\n",
      "  0.22677689 0.22649203 0.22621349 0.22594093 0.22567403 0.22541251\n",
      "  0.22515609 0.22490453 0.22465758 0.22441503 0.22417668 0.22394233\n",
      "  0.22371181 0.22348495 0.2232616  0.2230416  0.22282482 0.22261113\n",
      "  0.22240041 0.22219254 0.22198741 0.22178493 0.22158499 0.2213875\n",
      "  0.22119238 0.22099954 0.22080891 0.22062041 0.22043397 0.22024953\n",
      "  0.22006702 0.21988638 0.21970756 0.21953049 0.21935513 0.21918144\n",
      "  0.21900935 0.21883882 0.21866982 0.2185023  0.21833622 0.21817154\n",
      "  0.21800823 0.21784625 0.21768558 0.21752616 0.21736799 0.21721102\n",
      "  0.21705523 0.21690058 0.21674707 0.21659465 0.21644332 0.21629303\n",
      "  0.21614377 0.21599552 0.21584826 0.21570197 0.21555663 0.21541221\n",
      "  0.21526871 0.2151261  0.21498436 0.21484349 0.21470346 0.21456427\n",
      "  0.21442588 0.2142883  0.21415151 0.21401549 0.21388023 0.21374572\n",
      "  0.21361194 0.21347889 0.21334655 0.21321492 0.21308397 0.21295371\n",
      "  0.21282411 0.21269518 0.21256689 0.21243925 0.21231224 0.21218585\n",
      "  0.21206008 0.21193491 0.21181034 0.21168637 0.21156297 0.21144015\n",
      "  0.2113179  0.21119621 0.21107507 0.21095448 0.21083443 0.21071491\n",
      "  0.21059592 0.21047746 0.2103595  0.21024206 0.21012512 0.21000868\n",
      "  0.20989273 0.20977727 0.20966229 0.20954779 0.20943376 0.20932019\n",
      "  0.20920709 0.20909445 0.20898225 0.20887051 0.20875921 0.20864835\n",
      "  0.20853793 0.20842794 0.20831837 0.20820923 0.20810051 0.2079922\n",
      "  0.20788431 0.20777682 0.20766974 0.20756306 0.20745677 0.20735088\n",
      "  0.20724538 0.20714027 0.20703554 0.2069312  0.20682723 0.20672364\n",
      "  0.20662042 0.20651757 0.20641508 0.20631296 0.20621119 0.20610979\n",
      "  0.20600874 0.20590804 0.2058077  0.2057077  0.20560804 0.20550873\n",
      "  0.20540975 0.20531111 0.20521281 0.20511484 0.2050172  0.20491989\n",
      "  0.2048229  0.20472624 0.2046299  0.20453387 0.20443817 0.20434277\n",
      "  0.2042477  0.20415293 0.20405847 0.20396432 0.20387047 0.20377692\n",
      "  0.20368368 0.20359073 0.20349808 0.20340573 0.20331367 0.20322191\n",
      "  0.20313043 0.20303924 0.20294834 0.20285772 0.20276739 0.20267733\n",
      "  0.20258756 0.20249807 0.20240885 0.20231991 0.20223124 0.20214284\n",
      "  0.20205472 0.20196686 0.20187927 0.20179195 0.20170489 0.2016181\n",
      "  0.20153157 0.20144529 0.20135928 0.20127352 0.20118803 0.20110278\n",
      "  0.20101779 0.20093305 0.20084857 0.20076433 0.20068034 0.2005966\n",
      "  0.2005131  0.20042985 0.20034685 0.20026408 0.20018156 0.20009928\n",
      "  0.20001723 0.19993542 0.19985385 0.19977252 0.19969142 0.19961055\n",
      "  0.19952991 0.19944951 0.19936934 0.19928939 0.19920967 0.19913018\n",
      "  0.19905091 0.19897187 0.19889305 0.19881445 0.19873608 0.19865793\n",
      "  0.19857999 0.19850227 0.19842477 0.19834749 0.19827042 0.19819357\n",
      "  0.19811693 0.19804051 0.19796429 0.19788829 0.1978125  0.19773691\n",
      "  0.19766153 0.19758636 0.1975114  0.19743664 0.19736209 0.19728774\n",
      "  0.19721359 0.19713965 0.1970659  0.19699236 0.19691902 0.19684587\n",
      "  0.19677292 0.19670017 0.19662762 0.19655526 0.19648309 0.19641112\n",
      "  0.19633934 0.19626776 0.19619636 0.19612516 0.19605415 0.19598332\n",
      "  0.19591268 0.19584223 0.19577197 0.1957019  0.19563201 0.1955623\n",
      "  0.19549278 0.19542344 0.19535428 0.19528531 0.19521651 0.1951479\n",
      "  0.19507946 0.19501121 0.19494313 0.19487523 0.19480751 0.19473996\n",
      "  0.19467259 0.1946054  0.19453838 0.19447153 0.19440485 0.19433835\n",
      "  0.19427202 0.19420586 0.19413987 0.19407405 0.1940084  0.19394292\n",
      "  0.1938776  0.19381245 0.19374747 0.19368266 0.19361801 0.19355352\n",
      "  0.1934892  0.19342504 0.19336105 0.19329722 0.19323355 0.19317004\n",
      "  0.19310669 0.1930435  0.19298047 0.1929176  0.19285489 0.19279233\n",
      "  0.19272994 0.1926677  0.19260561 0.19254368 0.19248191 0.19242029\n",
      "  0.19235882 0.19229751 0.19223635 0.19217534 0.19211449 0.19205378\n",
      "  0.19199323 0.19193282 0.19187257 0.19181246 0.19175251 0.1916927\n",
      "  0.19163304 0.19157352 0.19151416 0.19145493 0.19139586 0.19133693\n",
      "  0.19127814 0.1912195  0.191161   0.19110264 0.19104443 0.19098636\n",
      "  0.19092843 0.19087064 0.19081299 0.19075549 0.19069812 0.19064089\n",
      "  0.1905838  0.19052685 0.19047003 0.19041336 0.19035682 0.19030042\n",
      "  0.19024415 0.19018802 0.19013202 0.19007616 0.19002043 0.18996484\n",
      "  0.18990938 0.18985405 0.18979886 0.18974379 0.18968886 0.18963406\n",
      "  0.18957939 0.18952485 0.18947044 0.18941616 0.18936201 0.18930799\n",
      "  0.1892541  0.18920033 0.18914669 0.18909318 0.1890398  0.18898654\n",
      "  0.1889334  0.1888804  0.18882751 0.18877475 0.18872212 0.18866961\n",
      "  0.18861722 0.18856496 0.18851282 0.1884608  0.1884089  0.18835712\n",
      "  0.18830547 0.18825393 0.18820252 0.18815122 0.18810005 0.18804899\n",
      "  0.18799806 0.18794724 0.18789654 0.18784595 0.18779549 0.18774514\n",
      "  0.18769491 0.18764479 0.18759479 0.1875449  0.18749513 0.18744548\n",
      "  0.18739594 0.18734651 0.1872972  0.187248   0.18719891 0.18714994\n",
      "  0.18710108 0.18705233 0.18700369 0.18695516 0.18690674 0.18685844\n",
      "  0.18681024 0.18676216 0.18671418 0.18666631 0.18661856 0.18657091\n",
      "  0.18652337 0.18647593 0.18642861 0.18638139 0.18633428 0.18628727\n",
      "  0.18624037 0.18619358 0.18614689 0.18610031 0.18605384 0.18600746\n",
      "  0.1859612  0.18591503 0.18586897 0.18582301 0.18577716 0.18573141\n",
      "  0.18568576 0.18564022 0.18559477 0.18554943 0.18550419 0.18545905\n",
      "  0.18541401 0.18536907 0.18532423 0.18527949 0.18523485 0.18519031\n",
      "  0.18514587 0.18510153 0.18505728 0.18501314 0.18496909 0.18492513\n",
      "  0.18488128 0.18483752 0.18479386 0.1847503  0.18470683 0.18466346\n",
      "  0.18462018 0.184577   0.18453391 0.18449092 0.18444802 0.18440522\n",
      "  0.18436251 0.18431989 0.18427737 0.18423493 0.1841926  0.18415035\n",
      "  0.1841082  0.18406614 0.18402417 0.18398229 0.1839405  0.18389881\n",
      "  0.1838572  0.18381569 0.18377426 0.18373293 0.18369168 0.18365053\n",
      "  0.18360946 0.18356848 0.18352759 0.18348679 0.18344608 0.18340545\n",
      "  0.18336491 0.18332446 0.1832841  0.18324382 0.18320363 0.18316353\n",
      "  0.18312351 0.18308358 0.18304373 0.18300397 0.18296429 0.1829247\n",
      "  0.1828852  0.18284578 0.18280644 0.18276718 0.18272801 0.18268893\n",
      "  0.18264992 0.182611   0.18257216 0.18253341 0.18249473 0.18245614\n",
      "  0.18241763 0.18237921 0.18234086 0.18230259 0.18226441 0.18222631\n",
      "  0.18218828 0.18215034 0.18211248 0.18207469 0.18203699 0.18199937\n",
      "  0.18196182 0.18192436 0.18188697 0.18184966 0.18181243 0.18177528\n",
      "  0.1817382  0.1817012  0.18166428 0.18162744 0.18159068 0.18155399\n",
      "  0.18151737 0.18148084 0.18144438 0.18140799 0.18137169 0.18133545\n",
      "  0.1812993  0.18126321 0.18122721 0.18119127 0.18115541 0.18111963\n",
      "  0.18108392 0.18104828 0.18101272 0.18097723 0.18094182 0.18090648\n",
      "  0.18087121 0.18083601 0.18080088 0.18076583 0.18073085 0.18069594\n",
      "  0.18066111 0.18062634 0.18059165 0.18055703 0.18052247 0.18048799\n",
      "  0.18045358 0.18041924 0.18038497 0.18035077 0.18031664 0.18028258\n",
      "  0.18024859 0.18021467 0.18018082 0.18014704 0.18011332 0.18007967\n",
      "  0.1800461  0.18001259 0.17997914 0.17994577 0.17991246 0.17987922\n",
      "  0.17984605 0.17981295 0.17977991 0.17974694 0.17971403 0.1796812\n",
      "  0.17964842 0.17961572 0.17958308 0.1795505  0.17951799 0.17948555\n",
      "  0.17945317 0.17942086 0.17938861 0.17935642 0.1793243  0.17929225\n",
      "  0.17926026 0.17922833 0.17919647 0.17916467 0.17913293 0.17910126\n",
      "  0.17906965 0.1790381  0.17900662 0.17897519 0.17894384 0.17891254\n",
      "  0.1788813  0.17885013 0.17881902 0.17878797 0.17875698 0.17872606\n",
      "  0.17869519 0.17866439 0.17863364 0.17860296 0.17857234 0.17854178\n",
      "  0.17851128 0.17848083 0.17845045 0.17842013 0.17838987 0.17835967\n",
      "  0.17832952 0.17829944 0.17826942 0.17823945 0.17820954 0.17817969\n",
      "  0.1781499  0.17812017 0.1780905  0.17806088 0.17803132 0.17800182\n",
      "  0.17797238 0.17794299 0.17791366 0.17788439 0.17785518 0.17782602\n",
      "  0.17779692 0.17776788 0.17773889 0.17770996 0.17768108 0.17765226\n",
      "  0.1776235  0.17759479 0.17756613 0.17753754 0.17750899 0.17748051\n",
      "  0.17745207 0.1774237  0.17739537 0.17736711 0.17733889 0.17731073\n",
      "  0.17728263 0.17725458 0.17722658 0.17719863 0.17717074 0.17714291\n",
      "  0.17711512 0.17708739 0.17705972 0.17703209 0.17700452 0.176977\n",
      "  0.17694954 0.17692212 0.17689476 0.17686745 0.17684019 0.17681299\n",
      "  0.17678583 0.17675873 0.17673168 0.17670468 0.17667773 0.17665083\n",
      "  0.17662399 0.17659719 0.17657045 0.17654375 0.17651711 0.17649052\n",
      "  0.17646398 0.17643748 0.17641104 0.17638465 0.1763583  0.17633201\n",
      "  0.17630577 0.17627957 0.17625343 0.17622733 0.17620128 0.17617528\n",
      "  0.17614933 0.17612343 0.17609758 0.17607178 0.17604602 0.17602031\n",
      "  0.17599465 0.17596904 0.17594348 0.17591796 0.17589249 0.17586707\n",
      "  0.1758417  0.17581637 0.17579109 0.17576586 0.17574067 0.17571553\n",
      "  0.17569044 0.1756654  0.1756404  0.17561545 0.17559054 0.17556568\n",
      "  0.17554086 0.1755161  0.17549137 0.1754667  0.17544206 0.17541748\n",
      "  0.17539294 0.17536844 0.17534399 0.17531959 0.17529523 0.17527091\n",
      "  0.17524664 0.17522241 0.17519823 0.17517409 0.17515    0.17512595\n",
      "  0.17510194 0.17507798 0.17505407 0.17503019 0.17500636 0.17498258\n",
      "  0.17495883 0.17493513 0.17491148 0.17488786 0.17486429 0.17484077\n",
      "  0.17481728 0.17479384 0.17477044 0.17474708 0.17472377 0.17470049\n",
      "  0.17467726 0.17465408 0.17463093 0.17460783 0.17458476 0.17456174\n",
      "  0.17453876 0.17451583 0.17449293 0.17447008 0.17444726 0.17442449\n",
      "  0.17440176 0.17437907 0.17435642 0.17433381 0.17431124 0.17428871\n",
      "  0.17426623 0.17424378 0.17422137 0.17419901 0.17417668 0.17415439\n",
      "  0.17413215 0.17410994 0.17408777 0.17406564 0.17404356 0.17402151\n",
      "  0.1739995  0.17397753 0.1739556  0.1739337  0.17391185 0.17389004\n",
      "  0.17386826 0.17384652 0.17382483 0.17380317 0.17378155 0.17375996\n",
      "  0.17373842 0.17371691 0.17369544 0.17367401 0.17365262 0.17363127\n",
      "  0.17360995 0.17358867 0.17356743 0.17354622 0.17352505 0.17350393\n",
      "  0.17348283 0.17346178 0.17344076 0.17341978 0.17339883 0.17337792\n",
      "  0.17335705 0.17333622 0.17331542 0.17329466 0.17327393 0.17325324\n",
      "  0.17323259 0.17321197 0.17319139 0.17317085 0.17315034 0.17312987\n",
      "  0.17310943 0.17308903 0.17306866 0.17304833 0.17302803 0.17300777\n",
      "  0.17298755 0.17296736 0.1729472  0.17292708 0.172907   0.17288695\n",
      "  0.17286693 0.17284695 0.172827   0.17280709 0.17278721 0.17276737\n",
      "  0.17274756 0.17272779 0.17270805 0.17268834 0.17266867 0.17264903\n",
      "  0.17262942 0.17260985 0.17259031 0.17257081 0.17255134 0.1725319\n",
      "  0.1725125  0.17249313 0.17247379 0.17245449 0.17243522 0.17241598\n",
      "  0.17239677 0.1723776  0.17235846 0.17233935 0.17232028 0.17230124\n",
      "  0.17228223 0.17226325 0.17224431 0.17222539 0.17220651 0.17218766\n",
      "  0.17216885 0.17215006 0.17213131 0.17211259 0.1720939  0.17207525\n",
      "  0.17205662 0.17203803 0.17201946 0.17200093 0.17198243 0.17196396\n",
      "  0.17194553 0.17192712 0.17190875 0.1718904  0.17187209 0.17185381\n",
      "  0.17183555 0.17181733 0.17179914 0.17178098 0.17176285 0.17174475\n",
      "  0.17172669 0.17170865 0.17169064 0.17167266 0.17165472 0.1716368\n",
      "  0.17161891 0.17160105 0.17158322 0.17156543 0.17154766 0.17152992\n",
      "  0.17151221 0.17149453 0.17147688 0.17145926 0.17144167 0.17142411\n",
      "  0.17140657 0.17138907 0.1713716  0.17135415 0.17133673 0.17131935\n",
      "  0.17130199 0.17128466 0.17126735 0.17125008 0.17123284 0.17121562\n",
      "  0.17119843 0.17118127 0.17116414 0.17114704]\n",
      " [1.73286795 0.28135662 0.2623118  0.25560666 0.25140143 0.24840401\n",
      "  0.24591858 0.24388813 0.24210845 0.24058804 0.23921987 0.23801818\n",
      "  0.23691675 0.23592945 0.23501186 0.23417609 0.23339095 0.23266644\n",
      "  0.23198011 0.2313398  0.23072927 0.23015433 0.22960332 0.22908022\n",
      "  0.22857688 0.22809565 0.22763113 0.22718426 0.22675182 0.22633355\n",
      "  0.22592796 0.2255338  0.22515097 0.22477736 0.22441399 0.22405809\n",
      "  0.22371154 0.22337104 0.22303915 0.22271215 0.22239314 0.22207809\n",
      "  0.22177048 0.22146608 0.22116865 0.2208738  0.2205855  0.22029928\n",
      "  0.22001923 0.21974087 0.21946832 0.21919714 0.21893145 0.21866687\n",
      "  0.21840749 0.21814901 0.21789546 0.21764265 0.21739452 0.21714699\n",
      "  0.21690391 0.21666134 0.216423   0.21618509 0.21595119 0.21571769\n",
      "  0.215488   0.21525867 0.21503297 0.2148076  0.21458568 0.21436411\n",
      "  0.2141458  0.21392784 0.21371298 0.21349849 0.21328695 0.21307579\n",
      "  0.21286743 0.21265949 0.21245419 0.21224934 0.21204701 0.21184515\n",
      "  0.21164568 0.21144673 0.21125003 0.21105388 0.21085988 0.21066646\n",
      "  0.21047508 0.21028431 0.21009547 0.2099073  0.20972094 0.20953527\n",
      "  0.20935134 0.20916812 0.20898655 0.20880573 0.20862647 0.20844798\n",
      "  0.20827097 0.20809477 0.20791997 0.20774599 0.20757335 0.20740154\n",
      "  0.20723102 0.20706134 0.20689288 0.20672528 0.20655885 0.20639327\n",
      "  0.20622883 0.20606524 0.20590273 0.20574108 0.20558047 0.20542072\n",
      "  0.20526196 0.20510406 0.20494712 0.20479103 0.20463587 0.20448154\n",
      "  0.20432811 0.20417551 0.20402378 0.20387287 0.2037228  0.20357353\n",
      "  0.20342508 0.20327741 0.20313055 0.20298445 0.20283914 0.20269458\n",
      "  0.20255077 0.20240771 0.20226539 0.20212379 0.20198291 0.20184274\n",
      "  0.20170328 0.20156451 0.20142643 0.20128904 0.20115231 0.20101626\n",
      "  0.20088086 0.20074612 0.20061202 0.20047857 0.20034575 0.20021355\n",
      "  0.20008198 0.19995103 0.19982069 0.19969095 0.19956182 0.19943327\n",
      "  0.19930532 0.19917795 0.19905117 0.19892496 0.19879931 0.19867424\n",
      "  0.19854973 0.19842577 0.19830237 0.19817951 0.1980572  0.19793543\n",
      "  0.1978142  0.19769349 0.19757332 0.19745368 0.19733455 0.19721594\n",
      "  0.19709785 0.19698027 0.19686319 0.19674662 0.19663055 0.19651498\n",
      "  0.1963999  0.19628531 0.19617121 0.19605759 0.19594445 0.1958318\n",
      "  0.19571962 0.19560791 0.19549667 0.19538589 0.19527558 0.19516574\n",
      "  0.19505635 0.19494741 0.19483893 0.19473089 0.1946233  0.19451616\n",
      "  0.19440946 0.1943032  0.19419737 0.19409198 0.19398702 0.19388249\n",
      "  0.19377838 0.1936747  0.19357144 0.1934686  0.19336617 0.19326416\n",
      "  0.19316256 0.19306137 0.19296059 0.19286021 0.19276023 0.19266065\n",
      "  0.19256148 0.19246269 0.1923643  0.19226631 0.1921687  0.19207147\n",
      "  0.19197464 0.19187818 0.19178211 0.19168641 0.19159109 0.19149615\n",
      "  0.19140157 0.19130737 0.19121354 0.19112007 0.19102697 0.19093422\n",
      "  0.19084184 0.19074982 0.19065815 0.19056684 0.19047589 0.19038528\n",
      "  0.19029502 0.19020511 0.19011554 0.19002632 0.18993744 0.1898489\n",
      "  0.1897607  0.18967283 0.1895853  0.1894981  0.18941124 0.1893247\n",
      "  0.18923849 0.18915261 0.18906705 0.18898181 0.1888969  0.18881231\n",
      "  0.18872803 0.18864407 0.18856042 0.18847709 0.18839407 0.18831136\n",
      "  0.18822896 0.18814686 0.18806507 0.18798358 0.1879024  0.18782151\n",
      "  0.18774093 0.18766064 0.18758065 0.18750096 0.18742156 0.18734245\n",
      "  0.18726363 0.1871851  0.18710685 0.1870289  0.18695123 0.18687384\n",
      "  0.18679673 0.18671991 0.18664336 0.18656709 0.1864911  0.18641539\n",
      "  0.18633994 0.18626477 0.18618988 0.18611525 0.18604089 0.1859668\n",
      "  0.18589297 0.18581941 0.18574612 0.18567308 0.18560031 0.18552779\n",
      "  0.18545554 0.18538354 0.1853118  0.18524031 0.18516908 0.1850981\n",
      "  0.18502737 0.1849569  0.18488667 0.18481669 0.18474695 0.18467746\n",
      "  0.18460822 0.18453922 0.18447046 0.18440194 0.18433367 0.18426563\n",
      "  0.18419783 0.18413026 0.18406293 0.18399584 0.18392898 0.18386235\n",
      "  0.18379595 0.18372978 0.18366385 0.18359814 0.18353265 0.1834674\n",
      "  0.18340237 0.18333756 0.18327297 0.18320861 0.18314447 0.18308055\n",
      "  0.18301684 0.18295336 0.18289009 0.18282704 0.1827642  0.18270158\n",
      "  0.18263917 0.18257697 0.18251498 0.18245321 0.18239164 0.18233028\n",
      "  0.18226913 0.18220819 0.18214745 0.18208691 0.18202658 0.18196646\n",
      "  0.18190653 0.18184681 0.18178728 0.18172796 0.18166883 0.1816099\n",
      "  0.18155117 0.18149264 0.18143429 0.18137615 0.18131819 0.18126043\n",
      "  0.18120286 0.18114549 0.1810883  0.1810313  0.18097449 0.18091786\n",
      "  0.18086143 0.18080518 0.18074911 0.18069323 0.18063753 0.18058201\n",
      "  0.18052668 0.18047153 0.18041656 0.18036177 0.18030715 0.18025272\n",
      "  0.18019846 0.18014438 0.18009047 0.18003674 0.17998319 0.1799298\n",
      "  0.17987659 0.17982355 0.17977069 0.17971799 0.17966547 0.17961311\n",
      "  0.17956092 0.1795089  0.17945705 0.17940536 0.17935384 0.17930249\n",
      "  0.17925129 0.17920027 0.1791494  0.1790987  0.17904816 0.17899778\n",
      "  0.17894755 0.17889749 0.17884759 0.17879785 0.17874826 0.17869883\n",
      "  0.17864956 0.17860044 0.17855148 0.17850267 0.17845402 0.17840552\n",
      "  0.17835717 0.17830897 0.17826093 0.17821303 0.17816529 0.17811769\n",
      "  0.17807025 0.17802295 0.1779758  0.17792879 0.17788193 0.17783522\n",
      "  0.17778865 0.17774223 0.17769595 0.17764982 0.17760383 0.17755798\n",
      "  0.17751227 0.1774667  0.17742127 0.17737599 0.17733084 0.17728583\n",
      "  0.17724096 0.17719623 0.17715163 0.17710718 0.17706285 0.17701867\n",
      "  0.17697461 0.1769307  0.17688691 0.17684326 0.17679974 0.17675636\n",
      "  0.17671311 0.17666998 0.17662699 0.17658413 0.1765414  0.1764988\n",
      "  0.17645632 0.17641398 0.17637176 0.17632967 0.17628771 0.17624587\n",
      "  0.17620416 0.17616257 0.17612111 0.17607977 0.17603856 0.17599747\n",
      "  0.1759565  0.17591565 0.17587493 0.17583433 0.17579384 0.17575348\n",
      "  0.17571324 0.17567312 0.17563312 0.17559323 0.17555347 0.17551382\n",
      "  0.17547429 0.17543487 0.17539557 0.17535639 0.17531732 0.17527837\n",
      "  0.17523953 0.17520081 0.1751622  0.1751237  0.17508532 0.17504705\n",
      "  0.17500889 0.17497084 0.1749329  0.17489507 0.17485736 0.17481975\n",
      "  0.17478225 0.17474486 0.17470758 0.17467041 0.17463335 0.17459639\n",
      "  0.17455954 0.1745228  0.17448616 0.17444963 0.1744132  0.17437688\n",
      "  0.17434066 0.17430455 0.17426854 0.17423264 0.17419683 0.17416113\n",
      "  0.17412553 0.17409004 0.17405464 0.17401935 0.17398416 0.17394906\n",
      "  0.17391407 0.17387918 0.17384438 0.17380969 0.17377509 0.17374059\n",
      "  0.17370619 0.17367188 0.17363768 0.17360357 0.17356955 0.17353563\n",
      "  0.17350181 0.17346808 0.17343445 0.17340091 0.17336747 0.17333412\n",
      "  0.17330086 0.1732677  0.17323463 0.17320165 0.17316876 0.17313597\n",
      "  0.17310327 0.17307065 0.17303813 0.1730057  0.17297336 0.17294111\n",
      "  0.17290895 0.17287688 0.17284489 0.172813   0.17278119 0.17274947\n",
      "  0.17271784 0.1726863  0.17265484 0.17262347 0.17259219 0.17256099\n",
      "  0.17252988 0.17249885 0.17246791 0.17243705 0.17240628 0.17237559\n",
      "  0.17234498 0.17231446 0.17228402 0.17225367 0.1722234  0.1721932\n",
      "  0.1721631  0.17213307 0.17210313 0.17207326 0.17204348 0.17201378\n",
      "  0.17198416 0.17195461 0.17192515 0.17189577 0.17186647 0.17183724\n",
      "  0.1718081  0.17177903 0.17175004 0.17172113 0.17169229 0.17166354\n",
      "  0.17163486 0.17160626 0.17157773 0.17154928 0.1715209  0.17149261\n",
      "  0.17146438 0.17143624 0.17140816 0.17138016 0.17135224 0.17132439\n",
      "  0.17129661 0.17126891 0.17124128 0.17121373 0.17118624 0.17115883\n",
      "  0.17113149 0.17110423 0.17107703 0.17104991 0.17102286 0.17099588\n",
      "  0.17096897 0.17094213 0.17091536 0.17088866 0.17086203 0.17083547\n",
      "  0.17080898 0.17078256 0.17075621 0.17072993 0.17070371 0.17067757\n",
      "  0.17065149 0.17062548 0.17059954 0.17057366 0.17054785 0.17052211\n",
      "  0.17049644 0.17047083 0.17044528 0.17041981 0.1703944  0.17036905\n",
      "  0.17034377 0.17031856 0.17029341 0.17026832 0.1702433  0.17021834\n",
      "  0.17019345 0.17016862 0.17014385 0.17011915 0.17009451 0.17006994\n",
      "  0.17004542 0.17002097 0.16999658 0.16997226 0.16994799 0.16992379\n",
      "  0.16989965 0.16987557 0.16985155 0.16982759 0.16980369 0.16977985\n",
      "  0.16975607 0.16973236 0.1697087  0.1696851  0.16966156 0.16963808\n",
      "  0.16961466 0.1695913  0.169568   0.16954476 0.16952157 0.16949844\n",
      "  0.16947537 0.16945236 0.16942941 0.16940651 0.16938367 0.16936089\n",
      "  0.16933816 0.16931549 0.16929288 0.16927032 0.16924782 0.16922537\n",
      "  0.16920298 0.16918065 0.16915837 0.16913615 0.16911398 0.16909186\n",
      "  0.1690698  0.1690478  0.16902585 0.16900395 0.16898211 0.16896032\n",
      "  0.16893858 0.1689169  0.16889527 0.1688737  0.16885217 0.1688307\n",
      "  0.16880929 0.16878792 0.16876661 0.16874535 0.16872414 0.16870298\n",
      "  0.16868187 0.16866082 0.16863981 0.16861886 0.16859796 0.16857711\n",
      "  0.16855631 0.16853556 0.16851486 0.16849421 0.16847361 0.16845306\n",
      "  0.16843256 0.16841211 0.16839171 0.16837135 0.16835105 0.16833079\n",
      "  0.16831059 0.16829043 0.16827032 0.16825026 0.16823025 0.16821028\n",
      "  0.16819036 0.16817049 0.16815067 0.1681309  0.16811117 0.16809149\n",
      "  0.16807185 0.16805227 0.16803272 0.16801323 0.16799378 0.16797438\n",
      "  0.16795502 0.16793571 0.16791645 0.16789723 0.16787806 0.16785893\n",
      "  0.16783984 0.16782081 0.16780181 0.16778286 0.16776396 0.1677451\n",
      "  0.16772629 0.16770751 0.16768879 0.1676701  0.16765147 0.16763287\n",
      "  0.16761432 0.16759581 0.16757734 0.16755892 0.16754054 0.1675222\n",
      "  0.16750391 0.16748566 0.16746745 0.16744928 0.16743116 0.16741307\n",
      "  0.16739503 0.16737703 0.16735908 0.16734116 0.16732329 0.16730545\n",
      "  0.16728766 0.16726991 0.1672522  0.16723453 0.1672169  0.16719932\n",
      "  0.16718177 0.16716426 0.1671468  0.16712937 0.16711198 0.16709463\n",
      "  0.16707733 0.16706006 0.16704283 0.16702564 0.16700849 0.16699138\n",
      "  0.16697431 0.16695728 0.16694028 0.16692333 0.16690641 0.16688953\n",
      "  0.16687269 0.16685589 0.16683912 0.1668224  0.16680571 0.16678906\n",
      "  0.16677245 0.16675587 0.16673933 0.16672283 0.16670637 0.16668994\n",
      "  0.16667355 0.1666572  0.16664088 0.1666246  0.16660836 0.16659215\n",
      "  0.16657598 0.16655985 0.16654375 0.16652769 0.16651166 0.16649567\n",
      "  0.16647972 0.1664638  0.16644791 0.16643206 0.16641625 0.16640047\n",
      "  0.16638473 0.16636902 0.16635335 0.16633771 0.16632211 0.16630654\n",
      "  0.166291   0.1662755  0.16626003 0.1662446  0.1662292  0.16621384\n",
      "  0.16619851 0.16618321 0.16616795 0.16615272 0.16613752 0.16612236\n",
      "  0.16610723 0.16609213 0.16607707 0.16606204 0.16604704 0.16603208\n",
      "  0.16601714 0.16600224 0.16598738 0.16597254 0.16595774 0.16594297\n",
      "  0.16592823 0.16591352 0.16589885 0.16588421 0.1658696  0.16585502\n",
      "  0.16584047 0.16582595 0.16581147 0.16579701 0.16578259 0.1657682\n",
      "  0.16575384 0.16573951 0.16572521 0.16571095 0.16569671 0.1656825\n",
      "  0.16566833 0.16565418 0.16564007 0.16562598 0.16561193 0.1655979\n",
      "  0.16558391 0.16556994 0.16555601 0.1655421  0.16552823 0.16551438\n",
      "  0.16550056 0.16548678 0.16547302 0.16545929 0.16544559 0.16543192\n",
      "  0.16541828 0.16540467 0.16539108 0.16537753 0.165364   0.1653505\n",
      "  0.16533703 0.16532359 0.16531018 0.16529679 0.16528344 0.16527011\n",
      "  0.16525681 0.16524354 0.16523029 0.16521708 0.16520389 0.16519073\n",
      "  0.16517759 0.16516449 0.16515141 0.16513836 0.16512533 0.16511234\n",
      "  0.16509937 0.16508642 0.16507351 0.16506062 0.16504776 0.16503492\n",
      "  0.16502211 0.16500933 0.16499657 0.16498384 0.16497114 0.16495846\n",
      "  0.16494581 0.16493319 0.16492059 0.16490802 0.16489547 0.16488295\n",
      "  0.16487046 0.16485799 0.16484555 0.16483313 0.16482074 0.16480837\n",
      "  0.16479603 0.16478371 0.16477142 0.16475915 0.16474691 0.1647347\n",
      "  0.16472251 0.16471034 0.1646982  0.16468608 0.16467399 0.16466192\n",
      "  0.16464988 0.16463786 0.16462587 0.1646139  0.16460196 0.16459004\n",
      "  0.16457814 0.16456627 0.16455442 0.16454259 0.16453079 0.16451902\n",
      "  0.16450726 0.16449553 0.16448383 0.16447215 0.16446049 0.16444885\n",
      "  0.16443724 0.16442565 0.16441409 0.16440254]\n",
      " [1.73286795 0.28560078 0.25262318 0.246599   0.24278255 0.24507496\n",
      "  0.2413728  0.24468495 0.24015769 0.24434685 0.24043047 0.24669608\n",
      "  0.24415695 0.25009974 0.24569287 0.25001487 0.24485623 0.2491334\n",
      "  0.24384481 0.24810867 0.24283085 0.2470863  0.24186162 0.24610894\n",
      "  0.24093878 0.24517564 0.24005813 0.24428256 0.23921431 0.24342453\n",
      "  0.23840273 0.24259729 0.23761957 0.24179719 0.23686161 0.24102123\n",
      "  0.23612618 0.24026687 0.23541105 0.23953195 0.23471429 0.23881467\n",
      "  0.23403428 0.23811346 0.23336962 0.23742699 0.2327191  0.23675409\n",
      "  0.23208166 0.23609376 0.23145639 0.2354451  0.23084246 0.23480734\n",
      "  0.23023916 0.23417979 0.22964586 0.23356185 0.22906198 0.23295296\n",
      "  0.22848703 0.23235264 0.22792053 0.23176045 0.22736209 0.23117599\n",
      "  0.22681131 0.23059892 0.22626788 0.2300289  0.22573147 0.22946565\n",
      "  0.22520181 0.22890889 0.22467863 0.22835838 0.22416169 0.22781389\n",
      "  0.22365078 0.22727522 0.22314569 0.22674216 0.22264623 0.22621455\n",
      "  0.22215223 0.22569222 0.22166352 0.22517502 0.22117996 0.2246628\n",
      "  0.22070139 0.22415543 0.22022768 0.22365279 0.21975871 0.22315476\n",
      "  0.21929436 0.22266123 0.21883451 0.2221721  0.21837907 0.22168727\n",
      "  0.21792793 0.22120665 0.217481   0.22073016 0.21703818 0.2202577\n",
      "  0.21659939 0.21978921 0.21616456 0.2193246  0.21573359 0.21886382\n",
      "  0.21530643 0.21840679 0.21488299 0.21795345 0.21446321 0.21750373\n",
      "  0.21404703 0.21705758 0.21363437 0.21661495 0.21322519 0.21617578\n",
      "  0.21281942 0.21574001 0.21241702 0.2153076  0.21201791 0.21487851\n",
      "  0.21162206 0.21445268 0.21122941 0.21403007 0.21083992 0.21361064\n",
      "  0.21045353 0.21319435 0.21007021 0.21278115 0.20968991 0.21237102\n",
      "  0.20931259 0.2119639  0.2089382  0.21155978 0.20856671 0.2111586\n",
      "  0.20819807 0.21076034 0.20783226 0.21036497 0.20746923 0.20997244\n",
      "  0.20710895 0.20958274 0.20675138 0.20919583 0.20639649 0.20881168\n",
      "  0.20604425 0.20843026 0.20569462 0.20805155 0.20534758 0.20767552\n",
      "  0.20500309 0.20730213 0.20466112 0.20693137 0.20432164 0.20656321\n",
      "  0.20398463 0.20619762 0.20365006 0.20583458 0.2033179  0.20547407\n",
      "  0.20298813 0.20511607 0.20266071 0.20476054 0.20233562 0.20440747\n",
      "  0.20201285 0.20405684 0.20169235 0.20370863 0.20137412 0.20336281\n",
      "  0.20105812 0.20301936 0.20074434 0.20267827 0.20043274 0.20233951\n",
      "  0.20012332 0.20200307 0.19981604 0.20166892 0.1995109  0.20133706\n",
      "  0.19920785 0.20100745 0.1989069  0.20068009 0.198608   0.20035495\n",
      "  0.19831116 0.20003202 0.19801634 0.19971127 0.19772353 0.19939271\n",
      "  0.19743271 0.1990763  0.19714387 0.19876203 0.19685697 0.19844989\n",
      "  0.19657202 0.19813986 0.19628898 0.19783193 0.19600785 0.19752608\n",
      "  0.1957286  0.1972223  0.19545122 0.19692056 0.1951757  0.19662087\n",
      "  0.19490202 0.1963232  0.19463016 0.19602754 0.1943601  0.19573387\n",
      "  0.19409185 0.1954422  0.19382537 0.19515249 0.19356065 0.19486474\n",
      "  0.19329769 0.19457894 0.19303646 0.19429507 0.19277696 0.19401312\n",
      "  0.19251917 0.19373308 0.19226308 0.19345494 0.19200867 0.19317868\n",
      "  0.19175593 0.1929043  0.19150486 0.19263178 0.19125543 0.19236112\n",
      "  0.19100764 0.1920923  0.19076147 0.19182531 0.19051692 0.19156014\n",
      "  0.19027397 0.19129678 0.19003261 0.19103522 0.18979283 0.19077545\n",
      "  0.18955462 0.19051746 0.18931797 0.19026125 0.18908286 0.19000679\n",
      "  0.1888493  0.18975409 0.18861727 0.18950314 0.18838676 0.18925391\n",
      "  0.18815775 0.18900641 0.18793025 0.18876063 0.18770424 0.18851656\n",
      "  0.18747972 0.18827419 0.18725667 0.1880335  0.18703508 0.18779451\n",
      "  0.18681496 0.18755718 0.18659628 0.18732153 0.18637905 0.18708753\n",
      "  0.18616325 0.18685519 0.18594888 0.18662449 0.18573592 0.18639542\n",
      "  0.18552438 0.18616799 0.18531424 0.18594218 0.1851055  0.18571798\n",
      "  0.18489815 0.18549539 0.18469218 0.18527441 0.1844876  0.18505502\n",
      "  0.18428438 0.18483721 0.18408253 0.18462099 0.18388203 0.18440634\n",
      "  0.18368289 0.18419326 0.1834851  0.18398175 0.18328864 0.18377179\n",
      "  0.18309352 0.18356337 0.18289973 0.1833565  0.18270727 0.18315117\n",
      "  0.18251612 0.18294737 0.18232629 0.1827451  0.18213777 0.18254434\n",
      "  0.18195055 0.1823451  0.18176463 0.18214736 0.18158    0.18195113\n",
      "  0.18139667 0.18175639 0.18121462 0.18156314 0.18103384 0.18137138\n",
      "  0.18085435 0.18118109 0.18067612 0.18099228 0.18049916 0.18080494\n",
      "  0.18032347 0.18061906 0.18014903 0.18043463 0.17997585 0.18025165\n",
      "  0.17980392 0.18007012 0.17963323 0.17989003 0.17946379 0.17971138\n",
      "  0.17929558 0.17953415 0.17912861 0.17935834 0.17896286 0.17918395\n",
      "  0.17879835 0.17901097 0.17863505 0.1788394  0.17847297 0.17866922\n",
      "  0.17831211 0.17850044 0.17815246 0.17833305 0.17799401 0.17816704\n",
      "  0.17783677 0.1780024  0.17768072 0.17783914 0.17752587 0.17767724\n",
      "  0.17737221 0.1775167  0.17721974 0.17735752 0.17706845 0.17719968\n",
      "  0.17691834 0.17704318 0.1767694  0.17688802 0.17662164 0.17673419\n",
      "  0.17647505 0.17658168 0.17632962 0.17643049 0.17618535 0.17628061\n",
      "  0.17604223 0.17613204 0.17590027 0.17598477 0.17575946 0.17583879\n",
      "  0.1756198  0.17569411 0.17548128 0.17555071 0.17534389 0.17540859\n",
      "  0.17520765 0.17526774 0.17507253 0.17512816 0.17493855 0.17498984\n",
      "  0.17480569 0.17485278 0.17467395 0.17471697 0.17454334 0.17458241\n",
      "  0.17441384 0.1744491  0.17428546 0.17431702 0.17415819 0.17418618\n",
      "  0.17403204 0.17405657 0.17390699 0.17392819 0.17378304 0.17380103\n",
      "  0.17366021 0.17367509 0.17353847 0.17355037 0.17341784 0.17342686\n",
      "  0.17329832 0.17330456 0.17317989 0.17318347 0.17306256 0.17306359\n",
      "  0.17294634 0.17294492 0.17283121 0.17282744 0.17271719 0.17271117\n",
      "  0.17260426 0.1725961  0.17249245 0.17248223 0.17238173 0.17236957\n",
      "  0.17227212 0.1722581  0.17216363 0.17214784 0.17205624 0.17203877\n",
      "  0.17194997 0.17193092 0.17184481 0.17182427 0.17174078 0.17171882\n",
      "  0.17163787 0.17161459 0.17153609 0.17151157 0.17143545 0.17140977\n",
      "  0.17133595 0.1713092  0.1712376  0.17120985 0.1711404  0.17111173\n",
      "  0.17104435 0.17101484 0.17094948 0.1709192  0.17085578 0.1708248\n",
      "  0.17076326 0.17073166 0.17067193 0.17063978 0.17058179 0.17054916\n",
      "  0.17049286 0.17045982 0.17040515 0.17037175 0.17031865 0.17028497\n",
      "  0.17023339 0.17019948 0.17014936 0.17011528 0.17006657 0.17003238\n",
      "  0.16998503 0.16995079 0.16990475 0.16987051 0.16982573 0.16979153\n",
      "  0.16974797 0.16971387 0.16967147 0.16963751 0.16959623 0.16956246\n",
      "  0.16952226 0.16948871 0.16944954 0.16941625 0.16937808 0.16934507\n",
      "  0.16930786 0.16927517 0.16923886 0.16920651 0.16917109 0.1691391\n",
      "  0.16910451 0.1690729  0.16903911 0.16900789 0.16897486 0.16894405\n",
      "  0.16891174 0.16888134 0.16884972 0.16881973 0.16878876 0.16875919\n",
      "  0.16872884 0.16869968 0.16866991 0.16864116 0.16861194 0.16858359\n",
      "  0.16855489 0.16852693 0.16849872 0.16847113 0.16844338 0.16841616\n",
      "  0.16838883 0.16836196 0.16833504 0.16830851 0.16828196 0.16825575\n",
      "  0.16822955 0.16820365 0.16817778 0.16815216 0.1681266  0.16810126\n",
      "  0.16807599 0.1680509  0.1680259  0.16800106 0.16797631 0.16795171\n",
      "  0.16792719 0.16790281 0.16787851 0.16785434 0.16783026 0.16780628\n",
      "  0.1677824  0.16775861 0.16773491 0.16771131 0.16768779 0.16766436\n",
      "  0.16764101 0.16761775 0.16759457 0.16757146 0.16754844 0.16752549\n",
      "  0.16750262 0.16747982 0.16745709 0.16743444 0.16741186 0.16738935\n",
      "  0.16736691 0.16734454 0.16732224 0.16730001 0.16727784 0.16725574\n",
      "  0.16723371 0.16721174 0.16718983 0.16716799 0.16714622 0.16712451\n",
      "  0.16710286 0.16708127 0.16705975 0.16703829 0.16701689 0.16699555\n",
      "  0.16697428 0.16695306 0.16693191 0.16691081 0.16688978 0.1668688\n",
      "  0.16684789 0.16682703 0.16680623 0.1667855  0.16676482 0.1667442\n",
      "  0.16672363 0.16670313 0.16668268 0.16666229 0.16664196 0.16662168\n",
      "  0.16660146 0.1665813  0.16656119 0.16654114 0.16652115 0.16650121\n",
      "  0.16648133 0.1664615  0.16644173 0.16642201 0.16640235 0.16638274\n",
      "  0.16636318 0.16634368 0.16632423 0.16630484 0.1662855  0.16626622\n",
      "  0.16624698 0.1662278  0.16620868 0.1661896  0.16617058 0.16615161\n",
      "  0.16613269 0.16611382 0.16609501 0.16607624 0.16605753 0.16603887\n",
      "  0.16602026 0.1660017  0.16598319 0.16596473 0.16594632 0.16592796\n",
      "  0.16590965 0.16589139 0.16587318 0.16585502 0.1658369  0.16581884\n",
      "  0.16580082 0.16578286 0.16576494 0.16574707 0.16572925 0.16571147\n",
      "  0.16569375 0.16567607 0.16565844 0.16564085 0.16562331 0.16560582\n",
      "  0.16558838 0.16557098 0.16555363 0.16553632 0.16551906 0.16550185\n",
      "  0.16548468 0.16546756 0.16545048 0.16543345 0.16541647 0.16539952\n",
      "  0.16538263 0.16536578 0.16534897 0.1653322  0.16531548 0.16529881\n",
      "  0.16528218 0.16526559 0.16524904 0.16523254 0.16521608 0.16519967\n",
      "  0.1651833  0.16516697 0.16515068 0.16513443 0.16511823 0.16510207\n",
      "  0.16508595 0.16506988 0.16505384 0.16503785 0.1650219  0.16500599\n",
      "  0.16499012 0.16497429 0.1649585  0.16494275 0.16492705 0.16491138\n",
      "  0.16489576 0.16488017 0.16486463 0.16484912 0.16483366 0.16481823\n",
      "  0.16480284 0.1647875  0.16477219 0.16475692 0.16474169 0.1647265\n",
      "  0.16471135 0.16469623 0.16468116 0.16466612 0.16465112 0.16463616\n",
      "  0.16462124 0.16460635 0.1645915  0.16457669 0.16456192 0.16454719\n",
      "  0.16453249 0.16451783 0.1645032  0.16448861 0.16447406 0.16445955\n",
      "  0.16444507 0.16443063 0.16441622 0.16440185 0.16438752 0.16437322\n",
      "  0.16435896 0.16434473 0.16433054 0.16431639 0.16430227 0.16428818\n",
      "  0.16427413 0.16426011 0.16424613 0.16423219 0.16421827 0.1642044\n",
      "  0.16419055 0.16417674 0.16416297 0.16414923 0.16413552 0.16412185\n",
      "  0.16410821 0.1640946  0.16408103 0.16406749 0.16405398 0.16404051\n",
      "  0.16402707 0.16401366 0.16400028 0.16398694 0.16397363 0.16396035\n",
      "  0.16394711 0.1639339  0.16392071 0.16390757 0.16389445 0.16388136\n",
      "  0.16386831 0.16385529 0.1638423  0.16382934 0.16381641 0.16380351\n",
      "  0.16379065 0.16377781 0.16376501 0.16375224 0.16373949 0.16372678\n",
      "  0.1637141  0.16370145 0.16368883 0.16367624 0.16366368 0.16365115\n",
      "  0.16363865 0.16362618 0.16361373 0.16360132 0.16358894 0.16357659\n",
      "  0.16356426 0.16355197 0.16353971 0.16352747 0.16351526 0.16350308\n",
      "  0.16349094 0.16347881 0.16346672 0.16345466 0.16344262 0.16343062\n",
      "  0.16341864 0.16340669 0.16339476 0.16338287 0.163371   0.16335916\n",
      "  0.16334735 0.16333557 0.16332381 0.16331208 0.16330038 0.16328871\n",
      "  0.16327706 0.16326544 0.16325385 0.16324228 0.16323074 0.16321923\n",
      "  0.16320775 0.16319629 0.16318485 0.16317345 0.16316207 0.16315071\n",
      "  0.16313939 0.16312808 0.16311681 0.16310556 0.16309433 0.16308314\n",
      "  0.16307196 0.16306082 0.1630497  0.1630386  0.16302753 0.16301649\n",
      "  0.16300547 0.16299447 0.1629835  0.16297256 0.16296164 0.16295074\n",
      "  0.16293987 0.16292902 0.1629182  0.16290741 0.16289663 0.16288589\n",
      "  0.16287516 0.16286446 0.16285379 0.16284314 0.16283251 0.16282191\n",
      "  0.16281133 0.16280077 0.16279024 0.16277973 0.16276925 0.16275879\n",
      "  0.16274835 0.16273793 0.16272754 0.16271717 0.16270683 0.16269651\n",
      "  0.16268621 0.16267593 0.16266568 0.16265545 0.16264524 0.16263506\n",
      "  0.16262489 0.16261475 0.16260464 0.16259454 0.16258447 0.16257442\n",
      "  0.16256439 0.16255438 0.1625444  0.16253444 0.1625245  0.16251458\n",
      "  0.16250468 0.1624948  0.16248495 0.16247512 0.16246531 0.16245552\n",
      "  0.16244575 0.16243601 0.16242628 0.16241658 0.16240689 0.16239723\n",
      "  0.16238759 0.16237797 0.16236837 0.1623588  0.16234924 0.1623397\n",
      "  0.16233019 0.16232069 0.16231122 0.16230176 0.16229233 0.16228291\n",
      "  0.16227352 0.16226415 0.16225479 0.16224546 0.16223615 0.16222685\n",
      "  0.16221758 0.16220833 0.1621991  0.16218988 0.16218069 0.16217151\n",
      "  0.16216236 0.16215322 0.16214411 0.16213501 0.16212593 0.16211688\n",
      "  0.16210784 0.16209882 0.16208982 0.16208084 0.16207187 0.16206293\n",
      "  0.16205401 0.1620451  0.16203621 0.16202735 0.1620185  0.16200966\n",
      "  0.16200085 0.16199206 0.16198328 0.16197453]\n",
      " [1.73286795 0.70850234 0.60684504 0.58899043 0.43237363 0.56387947\n",
      "  0.46297136 0.5050845  0.5011364  0.54187202 0.39627911 0.46312961\n",
      "  0.41784335 0.49146598 0.42718647 0.63590381 0.56143764 0.55440315\n",
      "  0.45174454 0.41796983 0.36231583 0.54756078 0.45313135 0.59390908\n",
      "  0.56099822 0.52969271 0.41043592 0.60357909 0.48195143 0.60880108\n",
      "  0.47585116 0.46336162 0.47929302 0.53287042 0.4481757  0.55798059\n",
      "  0.62097979 0.64599758 0.56112805 0.55772992 0.480508   0.43152259\n",
      "  0.45672184 0.5614524  0.70911183 0.62966328 0.51057111 0.53232444\n",
      "  0.34486298 0.443381   0.54496612 0.5165397  0.48346901 0.59911372\n",
      "  0.53263352 0.57404426 0.57377989 0.48676391 0.40106428 0.50283769\n",
      "  0.44298894 0.47775617 0.43432321 0.53822265 0.69276597 0.67421538\n",
      "  0.49772885 0.48079941 0.5894639  0.48658733 0.46693866 0.47976933\n",
      "  0.5288884  0.50177307 0.38213276 0.51848215 0.47254678 0.42474948\n",
      "  0.58729227 0.68826187 0.59928495 0.55464655 0.46934184 0.37937744\n",
      "  0.38057137 0.45849744 0.34838797 0.41054204 0.35736542 0.40643712\n",
      "  0.48348741 0.57640011 0.56121893 0.58826086 0.486508   0.44872693\n",
      "  0.44856726 0.44483121 0.45814957 0.48508271 0.47987355 0.45548855\n",
      "  0.39500212 0.45627242 0.45453294 0.50286648 0.48729306 0.48182052\n",
      "  0.42341268 0.4347019  0.54331781 0.45282796 0.37734961 0.42864604\n",
      "  0.30452176 0.37751695 0.44935268 0.43658946 0.48951307 0.43712454\n",
      "  0.38051286 0.43026074 0.25353808 0.3973431  0.38903934 0.40380426\n",
      "  0.56136033 0.5846181  0.42654692 0.43791786 0.36019222 0.38485395\n",
      "  0.43621788 0.40625377 0.42304457 0.42666347 0.45928788 0.46190329\n",
      "  0.35377856 0.36994479 0.41795198 0.40597115 0.42493895 0.45885395\n",
      "  0.44381011 0.43420635 0.46049994 0.44052074 0.41218054 0.46744189\n",
      "  0.55775177 0.47923059 0.47033768 0.49032889 0.48542311 0.48423534\n",
      "  0.37958439 0.41409654 0.46303926 0.38842365 0.40555634 0.44577254\n",
      "  0.47196741 0.41246052 0.39589561 0.39692484 0.38387551 0.3933611\n",
      "  0.30014891 0.36016283 0.42463444 0.41045052 0.36679513 0.33730625\n",
      "  0.37958669 0.36809987 0.42030545 0.45511763 0.4717577  0.44022728\n",
      "  0.43459674 0.41266059 0.36747559 0.38363982 0.27550245 0.35551009\n",
      "  0.40387502 0.46068427 0.51555982 0.40544492 0.35044503 0.40060684\n",
      "  0.26082042 0.30389503 0.31873078 0.34169497 0.28105447 0.35570944\n",
      "  0.31496063 0.3788614  0.44316775 0.40631396 0.36578184 0.37933676\n",
      "  0.29257243 0.35663891 0.34305698 0.42242029 0.51016227 0.41653126\n",
      "  0.31246066 0.36507814 0.2533599  0.35075871 0.29738744 0.33591038\n",
      "  0.29453168 0.33824452 0.31457079 0.34287078 0.2918456  0.3690063\n",
      "  0.41471935 0.37534602 0.37221656 0.3382551  0.25967135 0.33195166\n",
      "  0.25409896 0.33333068 0.29973752 0.33796777 0.28813089 0.35801873\n",
      "  0.32035288 0.32774507 0.31683459 0.36123574 0.4262724  0.39554818\n",
      "  0.35298538 0.34470179 0.31632325 0.35265507 0.32507344 0.36450855\n",
      "  0.43176036 0.39296825 0.415008   0.38521736 0.37577533 0.36292212\n",
      "  0.35313299 0.39750506 0.46566706 0.36852822 0.36878779 0.33493706\n",
      "  0.30568936 0.37854756 0.38466153 0.36857346 0.32806536 0.30886479\n",
      "  0.27136696 0.35065028 0.34638028 0.36611599 0.41862738 0.35747623\n",
      "  0.38761936 0.38176176 0.30566353 0.30645789 0.23546567 0.29262554\n",
      "  0.2891412  0.31382197 0.31400256 0.30887248 0.39951806 0.37966057\n",
      "  0.42160894 0.3768967  0.35203387 0.32247095 0.24952232 0.29761836\n",
      "  0.24901351 0.34604697 0.27772482 0.36882335 0.31154739 0.35668495\n",
      "  0.26639247 0.34120575 0.32292529 0.29925832 0.30053503 0.33160107\n",
      "  0.41383396 0.39976098 0.46181692 0.35322351 0.28191455 0.344079\n",
      "  0.24273568 0.29602969 0.38827506 0.39172868 0.36901731 0.29623293\n",
      "  0.31278621 0.36717678 0.28670051 0.29531471 0.28971284 0.3409471\n",
      "  0.34866014 0.33618938 0.34200347 0.33507601 0.29134992 0.29818788\n",
      "  0.33580718 0.36900057 0.38307679 0.3160684  0.36107213 0.33902199\n",
      "  0.2627868  0.31233849 0.26265597 0.30777565 0.26114097 0.33157047\n",
      "  0.27087076 0.30655321 0.27857682 0.27645015 0.34743916 0.34502582\n",
      "  0.44371681 0.33378705 0.3620369  0.34653025 0.43452239 0.37656753\n",
      "  0.40876287 0.32113458 0.3123786  0.3583751  0.43500231 0.34466501\n",
      "  0.36738719 0.3534645  0.31015574 0.31297761 0.34541172 0.36732163\n",
      "  0.35176987 0.3084952  0.29521411 0.31036309 0.25268193 0.30710258\n",
      "  0.25437086 0.27354116 0.28545515 0.34828152 0.4166682  0.31477619\n",
      "  0.32878932 0.30213529 0.28773937 0.34593488 0.38895769 0.30386141\n",
      "  0.2709964  0.29664897 0.23996973 0.29087719 0.23954728 0.289262\n",
      "  0.28376825 0.32070062 0.22865614 0.28062366 0.26821899 0.29621443\n",
      "  0.32074074 0.29070712 0.27132251 0.28392738 0.26540619 0.3321846\n",
      "  0.29306609 0.27356616 0.2887417  0.31407788 0.36086255 0.31850221\n",
      "  0.33096659 0.31812641 0.32143065 0.34397163 0.37021693 0.318587\n",
      "  0.31677684 0.30473686 0.23976729 0.28903217 0.24368913 0.27585632\n",
      "  0.24990794 0.28678827 0.25899301 0.30249064 0.28724469 0.29499141\n",
      "  0.29662509 0.28692742 0.28137568 0.32552172 0.34241997 0.29060528\n",
      "  0.29086451 0.31441355 0.25570707 0.25739089 0.24412041 0.30348545\n",
      "  0.26537081 0.27759434 0.33021303 0.37706409 0.46777569 0.30518788\n",
      "  0.28098631 0.30109211 0.32473185 0.31419248 0.28270465 0.29042496\n",
      "  0.29521479 0.32219208 0.30658438 0.28721601 0.27941173 0.28986122\n",
      "  0.25315449 0.27926857 0.24550064 0.27720295 0.25210401 0.28328914\n",
      "  0.28550081 0.28648508 0.31008548 0.33271054 0.38422205 0.31544967\n",
      "  0.33772638 0.32129691 0.34935988 0.33418379 0.38794224 0.31426686\n",
      "  0.29753365 0.30617104 0.29899986 0.28659521 0.32728259 0.34029353\n",
      "  0.3857711  0.29986166 0.28537364 0.29913058 0.30430127 0.29840163\n",
      "  0.26535259 0.29419403 0.28923953 0.28100852 0.28754662 0.31175744\n",
      "  0.30868502 0.29894276 0.2763293  0.29723827 0.29162334 0.30413809\n",
      "  0.30883404 0.30822339 0.29246714 0.30803257 0.29155513 0.290897\n",
      "  0.26554865 0.30094458 0.25739897 0.27976816 0.30527676 0.31408042\n",
      "  0.28155893 0.30134923 0.31401082 0.29589828 0.24954402 0.27454999\n",
      "  0.25271648 0.29145907 0.27362447 0.29297649 0.30855124 0.29726654\n",
      "  0.31340323 0.29523379 0.34302137 0.31183514 0.33119204 0.30044553\n",
      "  0.32562088 0.31264283 0.31501384 0.29697515 0.3276544  0.26634163\n",
      "  0.25893313 0.30231002 0.34114059 0.32850116 0.37793951 0.32004611\n",
      "  0.32731808 0.26875512 0.24286801 0.27327343 0.27757497 0.28845954\n",
      "  0.31246925 0.29351136 0.27407884 0.28040932 0.26654031 0.27620928\n",
      "  0.27282192 0.29665623 0.29706565 0.30016393 0.29581167 0.28622585\n",
      "  0.27352485 0.28089183 0.25413379 0.26078187 0.26577475 0.28170586\n",
      "  0.26429918 0.26462249 0.28921237 0.29034081 0.28513496 0.28688557\n",
      "  0.29712786 0.29216862 0.28830444 0.28961598 0.28635845 0.30699928\n",
      "  0.30633655 0.27998852 0.28253068 0.29430024 0.27246953 0.27518944\n",
      "  0.26211544 0.29414159 0.30255362 0.27169987 0.26587364 0.28571537\n",
      "  0.29781556 0.27464334 0.26490829 0.29396765 0.29560428 0.2678675\n",
      "  0.26851281 0.29222419 0.29391409 0.26236786 0.26874886 0.28800446\n",
      "  0.27911963 0.26649237 0.28451847 0.29064925 0.2840151  0.25936777\n",
      "  0.26678561 0.27990451 0.2646199  0.26086899 0.2925984  0.28764806\n",
      "  0.28281856 0.2777476  0.29529023 0.29168053 0.27778503 0.27042532\n",
      "  0.28250467 0.284508   0.27598659 0.27835097 0.29649097 0.27747844\n",
      "  0.26543953 0.28465425 0.29765585 0.2830648  0.27059363 0.27471951\n",
      "  0.28613044 0.27598329 0.26717813 0.27504834 0.29012179 0.27239555\n",
      "  0.2638844  0.27976831 0.2939765  0.27590423 0.2676747  0.27532295\n",
      "  0.28775592 0.27552568 0.2720231  0.28141671 0.28915203 0.27872275\n",
      "  0.27967963 0.28732642 0.2876822  0.26494802 0.26228723 0.2669456\n",
      "  0.26721659 0.27133886 0.28833091 0.27385032 0.27961997 0.27837761\n",
      "  0.28585889 0.27422154 0.27628555 0.27958547 0.29009269 0.27985406\n",
      "  0.28103721 0.27103828 0.2804936  0.27853732 0.28344628 0.269872\n",
      "  0.27465184 0.27557581 0.28229366 0.26349439 0.27027177 0.28036815\n",
      "  0.29095094 0.26861372 0.27095239 0.2756028  0.28181202 0.26013315\n",
      "  0.26703244 0.27714155 0.2839834  0.26110931 0.27056918 0.27546433\n",
      "  0.28282008 0.26270979 0.27175405 0.27461232 0.2821056  0.25986163\n",
      "  0.26877354 0.27488886 0.2818564  0.26330087 0.27556537 0.27980837\n",
      "  0.28452137 0.26049652 0.26947834 0.27102503 0.27134905 0.26006644\n",
      "  0.28022284 0.27578576 0.2791047  0.26032844 0.27445773 0.27205927\n",
      "  0.27767328 0.2630717  0.27439262 0.27436147 0.28175292 0.26104047\n",
      "  0.2718165  0.27599205 0.27921673 0.26201067 0.27513954 0.27446289\n",
      "  0.27721425 0.25946766 0.27264838 0.27697297 0.28025622 0.25896627\n",
      "  0.27297669 0.2709919  0.27665761 0.25951388 0.27283377 0.26898294\n",
      "  0.27687107 0.26044127 0.27110553 0.27350305 0.28257631 0.26077556\n",
      "  0.26988764 0.26761683 0.27598583 0.25850508 0.26961063 0.26897007\n",
      "  0.28093245 0.261116   0.27046927 0.26765936 0.2785435  0.25723826\n",
      "  0.26650742 0.26854124 0.2794939  0.25913231 0.27120461 0.26696694\n",
      "  0.27607451 0.25820302 0.27080028 0.26954917 0.28032744 0.25791754\n",
      "  0.26851773 0.26469298 0.27405108 0.25910931 0.27244392 0.2665784\n",
      "  0.2771588  0.25845541 0.27140974 0.26632568 0.27613706 0.25638173\n",
      "  0.2669957  0.26590622 0.28005152 0.25939632 0.26941877 0.26390597\n",
      "  0.27607843 0.25683348 0.26754656 0.26491339 0.27753366 0.25828549\n",
      "  0.27014572 0.26428931 0.27632298 0.25707597 0.26837242 0.26485045\n",
      "  0.27805768 0.25813807 0.26964739 0.26368105 0.27591358 0.25576598\n",
      "  0.26741064 0.26328502 0.27607822 0.25914764 0.27203615 0.26210656\n",
      "  0.27437128 0.25728461 0.26855368 0.26151399 0.27444586 0.25713412\n",
      "  0.27024962 0.26390489 0.27642725 0.2547189  0.26625074 0.26099386\n",
      "  0.27410956 0.25861997 0.27149994 0.25986812 0.27290048 0.25683743\n",
      "  0.27043948 0.26226651 0.27479544 0.25566506 0.26915392 0.25970528\n",
      "  0.27254525 0.25823594 0.27213998 0.25906967 0.27029356 0.25551396\n",
      "  0.26991584 0.26110332 0.27484554 0.25455401 0.26631589 0.2606729\n",
      "  0.27567891 0.25659768 0.2682508  0.25740687 0.27164363 0.25573634\n",
      "  0.26889121 0.26043149 0.27446854 0.25520839 0.26837639 0.25938962\n",
      "  0.27361548 0.25393486 0.26638613 0.26046997 0.27437567 0.25450078\n",
      "  0.26775315 0.25722853 0.27049491 0.25600737 0.27044204 0.25769919\n",
      "  0.27117735 0.25680608 0.27036991 0.25540351 0.26920364 0.25467131\n",
      "  0.2685086  0.25877176 0.27257004 0.25468966 0.26888922 0.25455392\n",
      "  0.26821985 0.25708574 0.27144711 0.25541422 0.26891632 0.25514671\n",
      "  0.26999839 0.25705237 0.27121012 0.25355492 0.26684665 0.25564648\n",
      "  0.27102713 0.25575943 0.26818463 0.25455185 0.27069297 0.2544662\n",
      "  0.26737568 0.25649589 0.27146953 0.2532541  0.26671356 0.25579792\n",
      "  0.27100505 0.2532875  0.26710113 0.25680862 0.27172813 0.25228202\n",
      "  0.26539874 0.25444285 0.26963696 0.25484524 0.26859724 0.25351044\n",
      "  0.26826516 0.25354274 0.26828974 0.25441537 0.26862194 0.25336914\n",
      "  0.26820426 0.25453454 0.2694129  0.25278957 0.26617803 0.25427496\n",
      "  0.27140536 0.25294204 0.26457081 0.25405004 0.27059412 0.25229073\n",
      "  0.26596889 0.25317424 0.26846795 0.25311584 0.26757518 0.2541282\n",
      "  0.26828906 0.25208294 0.26779568 0.25306346 0.26667272 0.25206153\n",
      "  0.26815429 0.2534756  0.26694868 0.25193782 0.26749998 0.25201714\n",
      "  0.26692529 0.25289664 0.26730394 0.25206931 0.26756784 0.251259\n",
      "  0.26553235 0.25292357 0.26895463 0.25117655 0.26556421 0.25381704\n",
      "  0.26945038 0.24994303 0.26390742 0.25220757 0.26851016 0.25163415\n",
      "  0.26495628 0.25147804 0.26785816 0.25019289 0.26431287 0.25312206\n",
      "  0.26847064 0.24986314 0.26503152 0.25139691 0.26663102 0.25117361\n",
      "  0.26564544 0.250807   0.26636814 0.25171567 0.26648694 0.24978029\n",
      "  0.26503004 0.25032419 0.2658373  0.25187788 0.2667065  0.24925715\n",
      "  0.26444297 0.25139137 0.26707366 0.24984779 0.26430582 0.25041027\n",
      "  0.26679215 0.25057224 0.26434624 0.25054484]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "NCost = int(models[0.003][\"num_iterations\"])#/100)\n",
    "\n",
    "costarray_full = np.zeros((len(learning_rates),NCost))\n",
    "costarray_single = np.zeros(NCost)\n",
    "\n",
    "#print (NCost)\n",
    "for i in range(6):#len(learning_rates)):\n",
    "    costarray_single = np.zeros(NCost)\n",
    "    for j in range(NCost):\n",
    "        #print (j)\n",
    "        costarray_single[j] = np.mean(np.squeeze(models[learning_rates[i]][\"costs\"][j])) \n",
    "    costarray_full[i] = costarray_single\n",
    "    plt.plot(costarray_full[i], label= str(models[learning_rates[i]][\"learning_rate\"]),alpha=0.7)\n",
    "    #print (np.squeeze(models[i][\"costs\"][2]))\n",
    "\n",
    "#plt.plot(costarray_full[i], label= str(models[0.001][\"learning_rate\"]), alpha=1)\n",
    "#plt.plot(np.squeeze(models[0.001][\"costs\"][1]), label= str(models[0.001][\"learning_rate\"]))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()\n",
    "\n",
    "print (costarray_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "#grid=[x for x in range(7)]\n",
    "i = 0\n",
    "for gg,graph in enumerate(costarray_full[0:6]):\n",
    "    lw=10-8*gg/len(costarray_full)\n",
    "    ls=['-','--','-.',':'][gg%4]\n",
    "    #plt.plot(grid,graph,label=str(models[learning_rates[i]][\"learning_rate\"]), linestyle=ls, linewidth=lw)\n",
    "    plt.plot(graph,label=str(models[learning_rates[i]][\"learning_rate\"]), linestyle=ls, linewidth=lw)\n",
    "    i = i+1\n",
    "    \n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='center right', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  15.807164499999999\n",
      "-------------------------------------------------------\n",
      "training Score:  0.9795717592592592\n",
      "testingg Score:  0.9755413668457147\n",
      "train accuracy: 97.95717592592592 %\n",
      "test accuracy: 97.55202526941657 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "#from sklearn.preprocessing import StandardScaler # data normalization\n",
    "#X_var = StandardScaler().fit(X_var).transform(x_train.T)\n",
    "\n",
    "TrainScore = []\n",
    "TestScore = []\n",
    "NgxNt = y_train.shape[0]\n",
    "m_Tr = x_train.shape[1]\n",
    "m_Ts = x_test.shape[1]\n",
    "\n",
    "Y_hat_tr_skln_pred = np.zeros((m_Tr,NgxNt))\n",
    "Y_hat_ts_skln_pred = np.zeros((m_Ts,NgxNt))\n",
    "\n",
    "start = timer()\n",
    "for i in range(NgxNt):\n",
    "    #print (\"Ng*Nt: \",i)   \n",
    "    \n",
    "    if set([0,1]).issubset(set(y_train[i])):      \n",
    "        \n",
    "        #logreg = MultiOutputRegressor(LogisticRegression(multi_class='multinomial', solver='lbfgs'))\n",
    "        logreg = LogisticRegression(random_state=0, solver='liblinear', max_iter = 100)\n",
    "        logreg.fit(x_train.T,y_train[i]) #original shape before transposed\n",
    "        Y_hat_tr_skln_pred[:,i] = logreg.predict(x_train.T)\n",
    "        TrainScore.append(logreg.score(x_train.T,y_train[i]))\n",
    "        Y_hat_ts_skln_pred[:,i] = logreg.predict(x_test.T)\n",
    "        TestScore.append(logreg.score(x_test.T,y_test[i]))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if set([0]).issubset(set(y_train[i])):\n",
    "            Y_hat_tr_skln_pred[:,i] = np.zeros(m_Tr)\n",
    "        else:\n",
    "            Y_hat_tr_skln_pred[:,i] = np.ones(m_Tr)\n",
    "        \n",
    "        if set([0]).issubset(set(y_test[i])):\n",
    "            Y_hat_ts_skln_pred[:,i] = np.zeros(m_Ts)\n",
    "        else:\n",
    "            Y_hat_ts_skln_pred[:,i] = np.ones(m_Ts)\n",
    "            \n",
    "        TrainScore.append(1)\n",
    "        TestScore.append(1)\n",
    "end = timer()\n",
    "print(\"training time: \",end - start)\n",
    "print (\"-------------------------------------------------------\")\n",
    "\n",
    "print(\"training Score: \", np.mean(TrainScore))\n",
    "print(\"testing Score: \", np.mean(TestScore))\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_train.T - Y_hat_tr_skln_pred)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_test.T - Y_hat_ts_skln_pred)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_round = np.around(x_test, decimals=4)\n",
    "x_test_round = x_test_round.T\n",
    "with open(\"demand24Bus24PrdTestSampleSKLRN4Ampl.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(x_test_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"commitment24Bus24PrdTestSampleSKLRN4Ampl.csv\",\"w+\",newline=\"\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(Y_hat_ts_skln_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is 0.01 \n",
      "train accuracy: 95.16864033907224 %\n",
      "test accuracy: 95.17634472888518 %\n",
      "training time:  8.177797299998929\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print (\"learning rate is 0.01 \")\n",
    "models[i] = model(x_train, y_train, x_test, y_test, num_iterations = 100, learning_rate = 0.01, print_cost = True)\n",
    "end = timer()\n",
    "print(\"training time: \",end - start)\n",
    "print (\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is:  0.01\n",
      "test accuracy: 97.44941049288876 %\n",
      "train accuracy: 97.4961069023569 %\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "i = 0.01\n",
    "print (\"learning rate is: \",i)\n",
    "w = models[i][\"w\"]\n",
    "b = models[i][\"b\"]\n",
    "A_prediction_test = predict(w, b, x_test)\n",
    "A_prediction_test = A_prediction_test.T\n",
    "    \n",
    "m = A_prediction_test.shape[0]\n",
    "Y_test_hackFull = np.zeros((m,A_prediction_test.shape[1]))\n",
    "P = 0.5\n",
    "\n",
    "for j in range(m):\n",
    "    for k in range(A_prediction_test.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A_prediction_test[j, k] >= P:\n",
    "            Y_test_hackFull[j, k] = 1\n",
    "            \n",
    "        else:\n",
    "            Y_test_hackFull[j, k] = 0\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_test.T - Y_test_hackFull)) * 100))\n",
    "    \n",
    "A_prediction_train = predict(w, b, x_train)\n",
    "A_prediction_train = A_prediction_train.T\n",
    "    \n",
    "m = A_prediction_train.shape[0]\n",
    "Y_train_hackFull = np.zeros((m,A_prediction_train.shape[1]))\n",
    "    \n",
    "for j in range(m):\n",
    "    for k in range(A_prediction_train.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A_prediction_train[j, k] >= P:\n",
    "            Y_train_hackFull[j, k] = 1\n",
    "            \n",
    "        else:\n",
    "            Y_train_hackFull[j, k] = 0\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_train.T - Y_train_hackFull)) * 100))\n",
    "print (\"-------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
